{"articles":[{"title":"CommunityLearning","img":"../../../img/article/2021-12-10-14-59-50.png","href":"ai/ai-5/3","des":"# CommunityLearning\r\n\r\n## 信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation by Deep Community Learning\r\n\r\n文章链接：[https://arxiv.org/pdf/2001.11207.pdf](https://arxiv.org/pdf/2001.11207.pdf)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n(社区学习， community learning)这篇文章通过训练多个子模型用于多个子任务，end-to-end trainable deep neural network with active interactions between multiple tasks。\r\n\r\n社区学习与多任务学习不同，后者试图在没有参与模块之间紧密互动的情况下平行实现多个目标。\r\nThe community learning is different from multi-task learning that attempts to achiev","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.490Z"},{"title":"BoxInst变量","img":"../../../img/article/2021-11-01-10-35-26.png","href":"ai/ai-5/4","des":"# BoxInst 变量\r\n本文简单介绍BoxInst 模型中所使用到的关键变量\r\n\r\n## 信息\r\n\r\n论文标题: BoxInst: High-Performance Instance Segmentation with Box Annotations\r\n\r\n论文链接：[https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html](https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html)\r\n\r\n发布时间: 2020-12 (CVPR 2021)\r\n\r\n## 创新点总结\r\n提出了一种高性能、仅使用边界框注释进行训练的任务级实例","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.490Z"},{"title":"ISTR","img":"../../../img/article/2022-02-26-14-06-17.png","href":"ai/ai-5/5","des":"# ISTR\r\n\r\n## 信息 \r\n文章链接：[https://arxiv.org/abs/2105.00637](https://arxiv.org/abs/2105.00637)\r\n\r\n发表时间：2021-05\r\n\r\n![](../../../img/article/2022-02-26-14-06-17.png)\r\n\r\n## 创新点简介\r\n本文设计了一款TransFormer结构，类比了Spacer RCNN的思想，使用固定数目的RoI对目标进行界框检测和实例分割。\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.490Z"},{"title":"BPR微调框","img":"../../../img/article/2022-03-22-16-30-46.png","href":"ai/ai-3/13","des":"# BPR微调框\r\n\r\n## 信息\r\n\r\n文章标题：Look Closer to Segment Better: Boundary Patch Refinement for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2104.05239](https://arxiv.org/abs/2104.05239)\r\n\r\n发表时间：2021-04\r\n\r\n\r\n## 背景\r\n\r\n在实例分割任务中，由于特征图的空间分辨率低，以及边界像素比例极低造成的不平衡问题，使得预测的实例掩码的边界通常是不精确的。\r\n\r\n## 创新点简介\r\n![](../../../img/article/2022-03-22-16-30-46.png)\r\n\r\n本文提出一个后处理 refinement 框架：BPR，用来改善基于任何实例分割模型结果的边界质量。BPR 在 Cityscapes 基准上比 Mask R-CNN 基线有明显的改进，特别是在边界感知指标上。此外，通过将 BPR 框架应用于 PolyTransform + SegFix 基线，在 Citysca","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.489Z"},{"title":"ZSI","img":"../../../img/article/2021-12-13-17-25-44.png","href":"ai/ai-3/14","des":"# ZSI\r\n\r\n## 信息\r\n\r\n文章标题：Zero-Shot Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2104.06601](https://arxiv.org/abs/2104.06601)\r\n\r\n发表时间：2021-04\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n通过类间关系，可以推测出没有见过的类。如下图，刀是学习过的，但是叉子没有学习过，它推理出来了。\r\n\r\n![](../../../img/article/2021-12-13-17-25-44.png)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.489Z"},{"title":"GAP","img":"../../../img/article/2021-12-04-12-33-29.png","href":"ai/ai-4/0","des":"# 全局平均池化 与 类激活图\r\n\r\n## 信息\r\n\r\n类激活图:[https:://arxiv.org/pdf/1512.04150.pdf](https:://arxiv.org/pdf/1512.04150.pdf)\r\n\r\n文章链接：[https:://arxiv.org/pdf/1512.04150.pdf](https:://arxiv.org/pdf/1512.04150.pdf)\r\n\r\n发表时间：2015-12\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n全连接的出现（左图），让每一个特征图节点和最终的输出节点产生联系，这种联系和注意力机制一样，会产生空间信息的丢失，于是便提出了全局均匀池化的概念，让模型输出某个类的概率之和某一层特征图有关。（使每一层特征输出的均值作为最后结果）\r\n\r\n![](../../../img/article/2021-12-04-12-33-29.png)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用\r\n> although image-level class labels indicate only the ex","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.489Z"},{"title":"CRF-RandWalk","img":"../../../img/article/2021-12-04-13-01-08.png","href":"ai/ai-4/1","des":"# CRF-RandWalk\r\n\r\n## 概率均匀化\r\n【本质】：设计一种概率转移方法，将图像中的密集概率向着整个物品进行扩散。也就是说通过计算两个特征像素之间的相似性，如果相似的话，就让当前像素上的概率和这个像素的概率进行均摊。\r\n\r\n## 条件随机场\r\n![](../../../img/article/2021-12-04-13-01-08.png)\r\n\r\n条件随机场通过“势函数”的引入，将初始的概率图进行转化。\r\n势函数包含了图片的像素色彩和位置信息\r\n\r\n## PCM\r\n![](../../../img/article/2021-12-04-13-18-36.png)\r\n\r\n图片来源于[https://arxiv.org/pdf/2004.04581v1](https://arxiv.org/pdf/2004.04581v1)\r\nPCM通过计算特征之间的相似程度，通过相似程度，进行概率转移。计算方式为余弦相似度。\r\n\r\n![](../../../img/article/2021-12-04-13-19-12.png)\r\n\r\n![](../../../img/article/20","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.489Z"},{"title":"BAP_NAL","img":"../../../img/article/2021-11-03-21-39-58.png","href":"ai/ai-4/2","des":"# BAP_NAL\r\n\r\n## 信息\r\n\r\n文章标题：Background-Aware Pooling and Noise-Aware Loss forWeakly-Supervised Semantic Segmentation\r\n\r\n文章链接：\r\n\r\n发表时间：\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n①提出了BAP（背景感知池）方法，能够在边界框内分辨出前景和背景，相比于GAP方法，不会只考虑到局部。\r\n②我们引入了一个噪音感知损失（NAL）来训练CNN的语义分割。\r\n\r\n**效果**：\r\n在PASCAL VOC 2012数据集上使用DeepLab-V1（VGG-16）与最先进的方法进行定量比较，以mIoU计。粗体数字表示最好的性能，下划线的数字是第二好的。\r\n`Image-level labels (10K) with Saliency (3K)`\r\n| 方法              | 价值 | 测试 |\r\n|------------------|------|------|\r\n| SeeNetNIPS’18    | 61.1 | 60.7 |\r\n| Fick","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.489Z"},{"title":"基础","img":"../../../img/article/2022-02-18-11-31-12.png","href":"ai/ai-5/0","des":"# 弱监督实例分割\r\n\r\n## 基本问题\r\n为解决人工标注实例所消耗大量时间的问题，弱监督实例分割(WSIS)利用更加简单的标签，例如检测框，图片分类标签来进行实例分割。\r\n\r\n## 标签类别\r\n弱监督标签分类通常分为以下的4种，分别是图片分类标签，边界框，点标注和涂鸦标注。 其中标注成本最小的图片分类，它仅仅提供了一张图片中所出现物品的分类信息，也叫做图像级别的标注。\r\n\r\n![](../../../img/article/2022-02-18-11-31-12.png)\r\n\r\n\r\n## 两大问题\r\n弱监督实例分割不同于语义分割，它既要对每个像素进行分类，又要区分不同的同类个体。\r\n\r\n![](../../../img/article/2022-02-18-19-57-14.png)\r\n\r\n1. 像素分类问题：对于没一个像素，都需要知道其属于哪一个类别，一般会使用到类激活图的方式进行分类。\r\n2. 同类物体区分问题：对于同一种类的不同个体，实例分割需要他们进行区分。常见的区分方法包括边界框区分，预测中心区分。\r\n\r\n## 经典流程\r\n一个完整的弱监督分割方法主要包含三个流程\r\n1. ","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.489Z"},{"title":"AssociativeEmbedding","img":"../../../img/article/2022-03-22-20-46-17.png","href":"ai/ai-3/5","des":"# Associative Embedding\r\n\r\n## 信息\r\n\r\n文章标题：Associative Embedding: End-to-End Learning for Joint Detection and Grouping\r\n\r\n文章链接：[https://proceedings.neurips.cc/paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html)\r\n\r\n发表时间：2017  (NIPS 2017)\r\n\r\n测试数据集： MPII 和 MS-COCO\r\n\r\n## 背景\r\n许多计算机视觉任务可以看作是联合的检测和分组，以关键点检测为例，都是检测较小的视觉单元（例如膝盖，手腕，头部），然后再并将它们分组到更大结构中。作者认为种方法可能是次优的, 因为检测和分组通常是紧密耦合的。\r\n\r\n## 创新点简介\r\n本文探讨了使","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T09:39:56.488Z"}]}