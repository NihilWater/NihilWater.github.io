{"articles":[{"title":"基础","img":"","href":"ai/ai-8/0","des":"# 目标检测算法\r\n目标检测算法，检测出一张图片上的目标物体，并通过矩形框进行标注。\r\n\r\n\r\n## 分类\r\n【是否有Anchor Box先验框】<br/>\r\n\r\n按照是否有Anchor Box先验框，可以分为Anchor-Base模型和Anchor-free模型，Anchor的提出，旨在通过先验信息，初步给出一个目标框的样子，便于模型回归。\r\nAnchor-Base的代表作是Faster-RCNN, SSD, YOLO-V2, YOLOV3;\r\nAnchor-free的代表作是YOLO-V1, FCOS\r\n\r\n【目标框选择和目标分类是否分离】<br/>\r\n\r\n按照目标框选择和目标分类是否分离, 可以分为一阶段模型和二阶段模型，one-stage 和 two-stage。\r\none-stage的代表作是YOLO，\r\ntwo-stage的代表作是Faster-RCNN","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"FCOS","img":"","href":"ai/ai-8/1","des":"# FCOS\r\n\r\n## 信息\r\n\r\n文章标题：FCOS: Fully Convolutional One-Stage Object Detection \r\n\r\n文章链接：[https://arxiv.org/pdf/1904.01355.pdf](https://arxiv.org/pdf/1904.01355.pdf)\r\n\r\n发表时间：2019-04\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n\r\n\r\n## 问题\r\n存在的问题，使用每一个预测框里的像素进行分类和预测，会导致背景参与计算，这样的运算是没有意义的。甚至是无效的。\r\n问题疑点：考虑到感受野的问题，肯能边上的特征像素也能够完成对物品框边缘的预测，尤其是边缘像素更有可能包含了物体边缘的信息，要小心处理\r\n\r\n\r\n## 引用","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"基础","img":"../../../img/article/2022-02-18-11-31-12.png","href":"ai/ai-5/0","des":"# 弱监督实例分割\r\n\r\n## 基本问题\r\n为解决人工标注实例所消耗大量时间的问题，弱监督实例分割(WSIS)利用更加简单的标签，例如检测框，图片分类标签来进行实例分割。\r\n\r\n## 标签类别\r\n弱监督标签分类通常分为以下的4种，分别是图片分类标签，边界框，点标注和涂鸦标注。 其中标注成本最小的图片分类，它仅仅提供了一张图片中所出现物品的分类信息，也叫做图像级别的标注。\r\n\r\n![](../../../img/article/2022-02-18-11-31-12.png)\r\n\r\n\r\n## 两大问题\r\n弱监督实例分割不同于语义分割，它既要对每个像素进行分类，又要区分不同的同类个体。\r\n\r\n![](../../../img/article/2022-02-18-19-57-14.png)\r\n\r\n1. 像素分类问题：对于没一个像素，都需要知道其属于哪一个类别，一般会使用到类激活图的方式进行分类。\r\n2. 同类物体区分问题：对于同一种类的不同个体，实例分割需要他们进行区分。常见的区分方法包括边界框区分，预测中心区分。\r\n\r\n## 经典流程\r\n一个完整的弱监督分割方法主要包含三个流程\r\n1. ","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.518Z"},{"title":"IRNet","img":"../../../img/article/2022-03-24-11-04-21.png","href":"ai/ai-5/1","des":"# IRNet\r\n\r\n## 信息\r\n\r\n文章标题：Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations\r\n\r\n文章链接：[http://arxiv.org/pdf/1904.05044](http://arxiv.org/pdf/1904.05044)\r\n\r\n发表时间：2019-04 (CPVR 2019)\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n\r\n![](../../../img/article/2022-03-24-11-04-21.png)\r\n\r\n本文使用全集标记，类激活图完成了实例分割任务。为解决类激活图无法区分实例，使用了pairwise semantic affinitie（成对语义相似关系）和lass-agnostic instance map (无类别实例映射)。(类不可知实例映射是一个粗糙的实例分割掩码，没有类标签，也没有精确的边界。另一方面，一对像素之间的语义亲和力是它们之间的类等价性的置信度。)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.518Z"},{"title":"MRP","img":"","href":"ai/ai-5/2","des":"# MRP\r\n\r\n## 信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation using Class Peak Response\r\n\r\n文章链接：[https://arxiv.org/pdf/1804.00880.pdf](https://arxiv.org/pdf/1804.00880.pdf)\r\n\r\n发表时间：2018-04\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n作者观察到类响应图的峰值大概率对应着一个真实的实例，先算出峰值位置，然后通过反向传播，获取峰值响应图（MRP）\r\n\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.518Z"},{"title":"CommunityLearning","img":"../../../img/article/2021-12-10-14-59-50.png","href":"ai/ai-5/3","des":"# CommunityLearning\r\n\r\n## 信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation by Deep Community Learning\r\n\r\n文章链接：[https://arxiv.org/pdf/2001.11207.pdf](https://arxiv.org/pdf/2001.11207.pdf)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n(社区学习， community learning)这篇文章通过训练多个子模型用于多个子任务，end-to-end trainable deep neural network with active interactions between multiple tasks。\r\n\r\n社区学习与多任务学习不同，后者试图在没有参与模块之间紧密互动的情况下平行实现多个目标。\r\nThe community learning is different from multi-task learning that attempts to achiev","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.518Z"},{"title":"FICS","img":"","href":"ai/ai-3/9","des":"","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.517Z"},{"title":"BlendMask","img":"../../../img/article/2022-02-25-15-11-58.png","href":"ai/ai-3/10","des":"# BlendMask\r\n\r\n## 信息\r\n\r\n文章标题：BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2001.0309](https://arxiv.org/abs/2001.0309)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 创新点简介\r\n本文使用提出了blender模型，将低层信息和高层信息融合，取得了更好的效果。其中高层信息会被制作成Attention map，而低层信息则包含更多的区分细节。轻量级模型在1080Ti上可达25FPS，用COCO数据集，mAP达34.2%。\r\n\r\n\r\n## 详细内容\r\n### 模型结构\r\n![](../../../img/article/2022-02-25-15-11-58.png)\r\n\r\n上文所说的低层信息，就是这里从骨干和FPN输出中提取出来的`Bases`，而所谓高层特征则是通过了一个个又通过了Tower之后又经过`Boxes Attns`模块的信息，他们通过Blender进行相乘，然后相加","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.517Z"},{"title":"SPRNet","img":"","href":"ai/ai-3/11","des":"# SPRNet\r\n\r\n## 信息\r\n\r\n文章标题：SPRNet: Single Pixel Reconstruction for One-stage Instance Segmentation\r\n\r\n文章链接：\r\n\r\n发表时间：\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.517Z"},{"title":"CondInst","img":"../../../img/article/2021-12-01-23-34-22.png","href":"ai/ai-3/12","des":"# CondInst\r\n\r\n## 信息\r\n\r\n文章标题：Conditional Convolutions for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2003.05664](https://arxiv.org/abs/2003.05664)\r\n\r\n发表时间：2020-03\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\nCondInst 在全卷积网络FCOS的基础上通过引入条件卷积，完成了对于实例分割任务的实现。Condinst completes the task of instance segmentation by introducing conditional convolution on the basis of full convolution network fcos.\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n![](../../../img/article/2021-12-01-23-34-22.png)\r\n\r\n### 条件卷积细节\r\n在计算边框和中心度分支的同级，引入条件卷积分支（一个3","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.517Z"}]}