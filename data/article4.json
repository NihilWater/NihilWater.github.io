{"articles":[{"title":"【有感而发01】怎样才算读好一片论文","img":"","href":"diary/diary-0/1","des":"# 【有感而发01】怎样才算读好一片论文\r\n<font color='gray'>2022-04-12</font>\r\n\r\n&emsp;&emsp;上周粗略的看了大概有24篇的文献，但感觉十分的轻浮。果然，和璇哥讨论时发现自己除了几篇印象深刻的文章以外，根本就讲不出来一片文章的所以然。\r\n\r\n&emsp;&emsp;于是我向璇哥请教，璇哥给我提了两点建议，我觉得挺有道理，有所感悟，所以先把它记下来，就我这忘性，不知道什么时候就想不起来了...\r\n\r\n## 1. 首先要看题目\r\n&emsp;&emsp;一篇好的文章，题目包含了它的主旨和创新。通过阅读标题，要明确作者的创新点，检验自己是否读懂一片文章的关键就是能不能说出题目中创新点的具体做法，能不能在论文的流程图里找到创新点对应的版块。\r\n\r\n## 2. 整理笔记时不要机翻\r\n&emsp;&emsp;机翻只是一种辅助理解的手段，直接使用机器翻译的文章，会破坏原本作者的行文逻辑。\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.770Z"},{"title":"安装","img":"","href":"docker/docker-0/0","des":"# Docker安装\r\n\r\n## Docker的意义\r\n\r\n传统的虚拟机存在着一些弊病。\r\n\r\n1. 虚拟机主体庞大：有时甚至大于你要在虚拟机上运行的应用。\r\n2. 启动时间长：虚拟机启动需要走完整的linux启动流程。\r\n3. 结构冗余：如果需要使用多个虚拟机，则其中操作系统部分虽然是一样的，但是也要单独运行。\r\n   \r\ndocker 提出了一整套的解决方案来优化和解决了这些问题\r\n1. 虚拟机主体庞大：docker 可以直接使用宿主机的操作系统，每一个docker只提供运行的必要库和应用。\r\n2. 启动时间长：由于宿主机的操作系统已被加载，所以启动docker没有启动虚拟机时加载linux的流程。\r\n3. 结构冗余：docker 将每个运行时环境进行拆分，一个docker可以运行多个依赖，而依赖之间也可以共享，解决了结构冗余的问题。\r\n\r\n> 参考地址 [https://docs.docker.com/engine/install/centos/](https://docs.docker.com/engine/install/centos/)\r\n\r\n<br>\r\n\r\n## dock","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.770Z"},{"title":"状态查询","img":"","href":"docker/docker-0/1","des":"# 【docker】查询命令\r\n\r\n## 常用命令\r\n|命令功能|命令|\r\n| --- | --- |\r\n| docker 配置信息 | docker info |\r\n| docker 版本 | docker version |\r\n| docker 版主 | docker 命令 --help |\r\n| 镜像列表 | docker images |\r\n| 镜像搜索 | docker search 镜像名 |\r\n| 正在运行 | docker ps |\r\n| 容器日志 | docker logs |\r\n\r\n\r\n## 常用位置\r\n【docker 配置文件】`/etc/docker/daemon.json`\r\n\r\n\r\n## 详情\r\n\r\n### docker images\r\n\r\n```shell\r\ndocker images -a  # 查看全部\r\ndocker images -q  # 查看id\r\ndocker images -aq # 查看全部id\r\n``` \r\n\r\n## docker ps\r\n```shell\r\ndocker ps [OPTIONS]\r\n# -a     查看全部现运行 +","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.770Z"},{"title":"introduction","img":"","href":"ai/ai-12/0","des":"# 图卷积神经网络\r\n## 意义\r\n使用神经网络来表达一张图上的信息。图相较于其他的数据结构，存在更加明显的结构特性。一张图的信息包含有4个方面，顶点的信息，边的信息，图整体的信息，图的连接信息。如今，大部分GNN在做的事情就是以一张图片的这些信息作为输入，得到一张输出图，输出图的结构信息与原图一样，但是顶点信息，边信息，整张图的信息表达会发生改变。\r\n\r\n## 信息的表达\r\n对于顶点信息，我们可以使用一个向量来进行表示。\r\n\r\n对于每一条边，我们同样可以使用一个向量来表示。\r\n对于全局信息，我们可以使用所有点的均值与所有边的均值进行表示，也可以使用一个和全部节点相连接的伪节点进行信息的表达。\r\n对于连接性，我们可以使用邻接表或者邻接矩阵来表示。\r\n\r\n## 案例说明\r\n【顶点分类问题】：已知一张图上有若干节点，需要对这些节点进行分类。\r\n① 最简单的方式，可能我们已经有了节点的向量表达，所以只需要对每个节点做一次全连接+softmax之类的分类网络就可以表示信息了。\r\n② 信息转化，假设顶点没有合理的向量表达，或者表达能力较弱，我们可以用边的","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.769Z"},{"title":"BAP_NAL","img":"../../../img/article/2021-11-03-21-39-58.png","href":"ai/ai-10/4","des":"# BAP边界感知池化和NAL感知损失\r\n\r\n## 基础信息\r\n\r\n文章标题：Background-Aware Pooling and Noise-Aware Loss forWeakly-Supervised Semantic Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2104.00905](https://arxiv.org/abs/2104.00905)\r\n\r\n发表时间：2021-04-02 (CVPR 2021)\r\n\r\n\r\n## 背景\r\n在使用边界框注释解决了弱监督语义分割（WSSS）的领域中，没有指定对象边界，因此很难训练卷积神经网络 (CNN) 进行语义分割。作者发现模型对边界框内外背景区域的感知具有相似性，这可以用来区分对象边界框内的前景和背景区域。\r\n\r\n## 创新点简介\r\n弱监督语义分割中的背景感知池化和噪声感知损失\r\n\r\n① 提出了BAP（背景感知池）方法，能够在边界框内分辨出前景和背景。具体做法是特征图上，利用边界框外的背景，计算出背景的特征表达。得到背景表达后，可以和边框内特征做相似度，对边界框内的背景和前景进行分割","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.768Z"},{"title":"【样本间信息学习】RCA","img":"../../../img/article/2022-04-12-16-49-56.png","href":"ai/ai-10/5","des":"# 【样本间信息学习】RCA\r\n\r\n## 基础信息\r\n\r\n文章标题：Regional Semantic Contrast and Aggregation for Weakly Supervised Semantic Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2203.09653](https://arxiv.org/abs/2203.09653)\r\n\r\n发表时间：2022-03-22\r\n\r\n\r\n## 背景\r\n\r\n从类别标签中学习语义分割的挑战在于很难从稀疏的类别标签中推断出目标密集的区域掩码。目前这方面的研究都只尝试在一个样本上或者一个样本组中进行，这严重限制了语义分割获取完整的注意力图。\r\n\r\n> Learning semantic segmentation from weakly-labeled (e.g., image tags only) data is challenging since it is hard to infer dense object regions from sparse semantic tags. Desp","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.768Z"},{"title":"PrototypicalNet","img":"","href":"ai/ai-11/0","des":"# PrototypicalNet\r\n\r\n## 基础信息\r\n\r\n文章标题：Prototypical Networks for Few-shot Learning\r\n\r\n文章链接：[https://arxiv.org/abs/1703.05175](https://arxiv.org/abs/1703.05175)\r\n\r\n发表时间：2017-03\r\n\r\n\r\n## 背景\r\n【度量学习】\r\n\r\n是一种学习两个样本（特征）之间相似性的学习方法。常见的度量有欧式距离、等。以上所提到的度量方法都是不可学习的，度量学习则使用神经网络来训练一个度量函数，这样做可以**对长度不同的片段进行比较**，也可以通过维度扩展的方式，来**寻找更深层次的相似性关系**。\r\n\r\n【度量空间】\r\n\r\n是指度量函数的集合\r\n\r\n【小样本学习】\r\n\r\n通过已经训练好的模型，在其基础之上加入新的分类，并且只有少量样本。在次基础上进行训练，使网络可以泛化到这些样本上。由于样本量很少，在新的类上很容易出先<font color=\"red\">过拟合的现象。</font>\r\n\r\n## 创新点简介\r\n本文使用原型网络`Prototy","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.768Z"},{"title":"GAP和CAM","img":"../../../img/article/2021-12-04-12-33-29.png","href":"ai/ai-10/1","des":"# 全局平均池化 与 类激活图\r\n\r\n## 基础信息\r\n\r\n类激活图:[https:://arxiv.org/pdf/1512.04150.pdf](https:://arxiv.org/pdf/1512.04150.pdf)\r\n\r\n文章链接：[https:://arxiv.org/pdf/1512.04150.pdf](https:://arxiv.org/pdf/1512.04150.pdf)\r\n\r\n发表时间：2015-12\r\n\r\n\r\n## 创新点简介\r\n全连接的出现（左图），让每一个特征图节点和最终的输出节点产生联系，这种联系和注意力机制一样，会产生空间信息的丢失，于是便提出了全局平均池化的概念，让模型输出某个类的概率之和某一层特征图有关。（使每一层特征输出的均值作为最后结果）。\r\n\r\n具体来说，CAM 通过将预训练的分类网络的全连接层，替换成了输出通道为类别数的卷积网络，对每个卷积网络的输出做全局平均池化，得到一个输出值，在这一组输出值上做softmax得到最终结果进行训练。\r\n\r\n![](../../../img/article/2021-12-04-12-33-29.png","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.767Z"},{"title":"CRF-RandWalk","img":"../../../img/article/2021-12-04-13-01-08.png","href":"ai/ai-10/2","des":"# CRF-RandWalk\r\n\r\n## 背景描述\r\n上文说到CAM方法，是一种在分类网络基础上替换网络的全连接层为，卷积+全局平均池化。由于对于一个目标是否属于一个类别来说，网络只需关注最有特点的地方，而不能完全覆盖一个目标。弱监督语义分割试图从CAM中得到掩码就需要让其关注整个目标，于是概均匀化的思想被提出。\r\n\r\n## 概率均匀化\r\n【本质】：设计一种概率转移方法，将图像中的密集概率向着整个物品进行扩散。也就是说通过计算两个特征像素之间的相似性，如果相似的话，就让当前像素上的概率和这个像素的概率进行均摊。\r\n\r\n## 条件随机场\r\n![](../../../img/article/2021-12-04-13-01-08.png)\r\n\r\n条件随机场通过“势函数”的引入，将初始的概率图进行转化。\r\n势函数包含了图片的像素色彩和位置信息\r\n\r\n## PCM\r\n![](../../../img/article/2021-12-04-13-18-36.png)\r\n\r\n图片来源于[https://arxiv.org/pdf/2004.04581v1](https://arxiv.org/pd","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.767Z"},{"title":"IRNet","img":"../../../img/article/2022-03-24-11-04-21.png","href":"ai/ai-9/3","des":"# IRNet\r\n\r\n## 基础信息\r\n\r\n文章标题：Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations\r\n\r\n文章链接：[http://arxiv.org/pdf/1904.05044](http://arxiv.org/pdf/1904.05044)\r\n\r\n发表时间：2019-04 (CPVR 2019)\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n\r\n![](../../../img/article/2022-03-24-11-04-21.png)\r\n\r\n本文使用全集标记，类激活图完成了实例分割任务。为解决类激活图无法区分实例，使用了pairwise semantic affinitie（成对语义相似关系）和lass-agnostic instance map (无类别实例映射)。(类不可知实例映射是一个粗糙的实例分割掩码，没有类标签，也没有精确的边界。另一方面，一对像素之间的语义亲和力是它们之间的类等价性的置信度。)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T15:21:09.766Z"}]}