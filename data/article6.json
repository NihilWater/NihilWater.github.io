{"articles":[{"title":"PANet","img":"../../../img/article/2022-03-24-22-55-05.png","href":"ai/ai-5/10","des":"# PANet\r\n\r\n## 基础信息\r\n\r\n文章标题：Path Aggregation Network for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/1803.01534](https://arxiv.org/abs/1803.01534)\r\n\r\n发表时间：2018-03 (CVPR-2018)\r\n\r\n\r\n## 背景\r\nMask-RCNN的信息传播还不够充分。低层特征到高层特征的传递路径过长，FPN中每个proposal只负责金字塔特定的一层，掩码预测只基于单一视角。\r\n\r\n## 创新点简介\r\n- 自底向上的路径增强，为了缩短信息传播路径，同时利用低层特征的精准定位信息\r\n- 动态特征池化，每个proposal利用金字塔所有层的特征，为了避免proposal的随意分配\r\n- 全连接层融合，为了给掩码预测增加信息来源，文中的说法是capture diffrent view\r\n\r\n![](../../../img/article/2022-03-24-22-55-05.png)\r\n\r\n## 详细内容\r\n\r\n### 模型结构","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.785Z"},{"title":"InstanceFCN","img":"../../../img/article/2022-03-07-22-06-33.png","href":"ai/ai-5/2","des":"# InstanceFCN\r\n\r\n## 基础信息\r\n\r\n文章标题：Instance-sensitive Fully Convolutional Networks\r\n\r\n文章链接：[https://link.springer.com/chapter/10.1007/978-3-319-46466-4_32](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_32)\r\n\r\n发表时间：2016-09 (ECCV 2016)\r\n\r\n## 背景\r\n对于以往的图像分割模型，由于卷积具有<font color=\"red\">位置的不敏感性</font>（对于相同的事物，在图像中处于不同的位置，卷积核的输出相同），导致了当两个相似的事物靠近时很难通过卷积来加以区分。\r\n\r\n## 创新点简介\r\n本文使用全卷积神经网络构建端到端的实例分割模型，它只分割每个实例，没有对实例进行分类。基于语义分割的模型，只有一种语义信息，如果两个实例距离贴就无法区分个体。这是由于卷积具有位置不变性造成的，作者使用滑动窗口，将窗口划分为9个小格（编号为1-9）","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.784Z"},{"title":"MaskRCNN","img":"../../../img/article/2021-10-30-13-42-24.png","href":"ai/ai-5/5","des":"# MaskRCNN\r\n\r\n## 基础信息\r\n\r\n文章标题：MaskRCNN\r\n\r\n文章链接：[Mask_RCNN](https://arxiv.org/pdf/1703.06870)\r\n\r\n发表时间：2017-03\r\n\r\n## 背景\r\n\r\n## 创新点简介\r\nMaskRCNN在FastRCNN的基础上加入了对于实例掩膜的预测分支，通过bounding box回归检测出每一个物品之后，再对回归框中的每一个像素进行分类，完成语义分割。这样的就实现了实例分割，即`目标检测+语义分割=实力分割`！\r\n\r\n## 详细内容\r\n\r\n### 实例分支训练\r\n训练时，通过当前得到的真实mask中的类别class_id，遍历所有的预测mask，找到class_id类别所对应的预测mask(前向传播中介绍过每个类别都有一个预测mask)，比较真实mask与预测mask每个像素点信息，用的是binary_cross_entropy二分类交叉熵损失函数\r\n![](../../../img/article/2021-10-30-13-42-24.png)\r\n\r\n**实例分割**\r\n![](../../../im","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.784Z"},{"title":"DANet","img":"../../../img/article/2022-02-18-17-29-10.png","href":"ai/ai-4/2","des":"# DANet \r\n\r\n## 基础信息\r\n\r\n文章标题：Dual Attention Network for Scene Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/1809.02983](https://arxiv.org/abs/1809.02983)\r\n\r\n发表时间：2018-09\r\n\r\n\r\n## 创新点简介\r\n本文使用自注意力机制，在语义分割上加入了位置自注意力机制和通道自注意力机制，根据作者表述，位置自注意力机制将图片中相似的内容进行互相增强`【原文：any two positions with similar features can contribute mutual improvement regardless of their distance in spatial dimension】`，而通道自注意力机制则可以捕获任意通道之间的互相依赖关系。`【原文：we use the similar self-attention mechanism to capture the channel dependencies betwee","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.783Z"},{"title":"基础","img":"../../../img/article/2021-11-03-13-35-03.png","href":"ai/ai-5/0","des":"# 基础\r\n语义分割是对图像中的每个像素划分出对应的类别，实现像素级别的分类。实例分割是在语义分割的基础上，进一步分割已划分类别的具体对象，即分割出实例。\r\n\r\n![](../../../img/article/2021-11-03-13-35-03.png)\r\n\r\n## 实例分割算法存在的挑战\r\n引用2016年InstanceCut中的话，实例分割存在着4个问题：\r\n1. 像语义分割一样将每个实例作为一种分类是没有意义的，如“第五个汽车”类。\r\n2. 一张图像中的实例数目差别很大，以城市景观数据集为例，每张图片可能存在0-120个不等的目标实例。 \r\n3. 实例分割相比于目标检测，需要更多的数进行表达，而不是仅仅中心点和长宽，4个值。\r\n4. 实例分割相比语义分割，需要更加细致的标签。\r\n\r\n## 实例分割和语义分割\r\n1. 能否完全使用语义分割？\r\n\r\n   不行，由于目标数目不固定，不能让一个实例就是一个类别。一般思路是先进行目标检测，后对检测狂内的物体进行语义分割，判断检测框内语义分割结果与哪个实例掩膜最接近就认为是哪实例。\r\n\r\n2. 存在的问题：两个实例重叠\r\n   \r\n ","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.783Z"},{"title":"sparse_RCNN","img":"../../../img/article/2022-03-15-15-25-43.png","href":"ai/ai-3/2","des":"# Sparse RCNN\r\n\r\n## 基础信息\r\n\r\n论文题目：Sparse R-CNN: End-to-End Object Detection with Learnable Proposals\r\n\r\n论文链接：[https://arxiv.org/abs/2011.12450](https://arxiv.org/abs/2011.12450)\r\n\r\n发表时间：2020-11\r\n\r\n## 创新\r\n\r\n使用可学习的100-300个边框来取代RPN（区域建议网络），实现了一个完全稀疏的端到端目标检测网络。\r\n\r\n\r\n## 详情\r\n\r\n### 稀疏和密集\r\n![](../../../img/article/2022-03-15-15-25-43.png)\r\n\r\n作者指出以前的目标检测都是每个特征像素做的，采用了“anchor boxes”机制，这会有十分密集的目标框（HWk个）产生，Faster RCNN 使用NMS筛选值的计算分类和边框回归的建议框，让一个密集的检测变得稀疏起来，但他仍然不能算是一个完全稀疏的目标检测方法（图b）。而本文作者所提出的Sparse RCNN则使用学习来的","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.782Z"},{"title":"GraphCut","img":"../../../img/article/2022-03-22-16-52-40.png","href":"ai/ai-4/0","des":"# GraphCut\r\n\r\n## 基础信息\r\n\r\n文章标题：Interactive Graph Cuts for Optimal Boundary & Region Segmentation of Objects in N-D Images\r\n\r\n文章链接：[https://www.csd.uwo.ca/~yboykov/Papers/iccv01.pdf](https://www.csd.uwo.ca/~yboykov/Papers/iccv01.pdf)\r\n\r\n发表时间：2001-07\r\n\r\n\r\n## 背景\r\n\r\n## 创新点简介\r\n用户标记部分像素作为“目标”或“背景”，为图像分割提供硬约束。此外，利用图像的边缘信息和区域信息作为软约束。图割方法是一种全局最优的N维图像分割方法。Graph cuts是一种能量优化算法，应用于前背景分割。它把图像分割问题当作图的最小割（min cut）问题。\r\n![](../../../img/article/2022-03-22-16-52-40.png)\r\n\r\n## 详细内容\r\n【具体步骤】\r\n- 首先，需要用户明确指出少量背景像素B和前景目标","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.782Z"},{"title":"initialize","img":"../../../img/article/2021-11-08-20-06-46.png","href":"ai/ai-1/4","des":"# pytorch权重初始化\r\n## 张量生成\r\n【全零张量】\r\n```py\r\ntorch.zeros((a,b,...))\r\n```\r\n\r\n\r\n## xavier 初始化\r\npytorch提供了uniform和normal两种\r\n\r\n![](../../../img/article/2021-11-08-20-06-46.png)\r\n\r\n使用normalize 进行初始化，随着网络的加深，梯度会消失。\r\n假设 $y = ax+b =w1x1+ w2x2 + ... + wnxn + b$\r\n\r\n对于y取方差有 $var(y) = var(w1x1) + var(w2x1) + var(w2x1) + var(b) = var(y) = N * var(wi) * var(xi)$\r\n所以，kaiming_normal 在初始化的时候让w在的分布都除以了$\\frac{1}{\\sqrt n}$, 来使得通过了全连接层的输出是和X同分布的。\r\n\r\n## kaiming 初始化\r\n针对ReLu 激活函数，有一般的输出，会被变成0，为了保持方差不变，会采用kaiming激活函数。在初始化的时候","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.781Z"},{"title":"loss","img":"","href":"ai/ai-1/5","des":"# loss 函数\r\n\r\n## 二次损失函数\r\n\r\n## sigmoid_focal_loss_jit\r\n```python\r\nsigmoid_focal_loss_jit(\r\n            pred,\r\n            class_target,\r\n            alpha=,\r\n            gamma=,\r\n            reduction=\"sum\"\r\n        )\r\n```\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.781Z"},{"title":"visible","img":"","href":"ai/ai-1/6","des":"# pytorch 可视化\r\n\r\n## 图片可视化\r\n```python \r\nfrom matplotlib import pyplot as plt\r\nimage = $image.cpu().clone()  # detach().numpy() 这里的 $image 要换成自己的变量名\r\n# image = image.permute(1,2,0)    # 这个是可选的，主要是要将图片的维度调正为(w, h, c)的形式\r\nplt.imshow(image)  # 准备图片\r\nplt.show()  # 展示图片\r\n```\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-05T07:17:26.781Z"}]}