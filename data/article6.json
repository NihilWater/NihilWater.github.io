{"articles":[{"title":"FICS","img":"","href":"ai/ai-3/9","des":"","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.204Z"},{"title":"基础","img":"../../../img/article/2021-11-03-13-35-03.png","href":"ai/ai-3/0","des":"# 基础\r\n\r\n![](../../../img/article/2021-11-03-13-35-03.png)\r\n\r\n## 实例分割和语义分割\r\n1. 能否完全使用语义分割？\r\n\r\n   不行，由于目标数目不固定，不能让一个实例就是一个类别。一般思路是先进行目标检测，后对检测狂内的物体进行语义分割，判断检测框内语义分割结果与哪个实例掩膜最接近就认为是哪实例。\r\n\r\n2. 存在的问题：两个实例重叠\r\n   \r\n   解决方案1：预测回归框，在回归框里进行二分类。\r\n   \r\n   解决方法2：预测中心，进行聚类。\r\n\r\n   \r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.203Z"},{"title":"InstanceFCN","img":"../../../img/article/2022-03-07-22-06-33.png","href":"ai/ai-3/1","des":"# InstanceFCN\r\n\r\n## 信息\r\n\r\n文章标题：Instance-sensitive Fully Convolutional Networks\r\n\r\n文章链接：[https://link.springer.com/chapter/10.1007/978-3-319-46466-4_32](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_32)\r\n\r\n发表时间：2016-09 (ECCV 2016)\r\n\r\n## 背景\r\n对于以往的图像分割模型，由于卷积具有<font color=\"red\">位置的不敏感性</font>（对于相同的事物，在图像中处于不同的位置，卷积核的输出相同），导致了当两个相似的事物靠近时很难通过卷积来加以区分。\r\n\r\n## 创新点简介\r\n本文使用全卷积神经网络构建端到端的实例分割模型，它只分割每个实例，没有对实例进行分类。基于语义分割的模型，只有一种语义信息，如果两个实例距离贴就无法区分个体。这是由于卷积具有位置不变性造成的，作者使用滑动窗口，将窗口划分为9个小格（编号为1-9），每","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.203Z"},{"title":"loss","img":"","href":"ai/ai-1/3","des":"# loss 函数\r\n\r\n## 二次损失函数\r\n\r\n## sigmoid_focal_loss_jit\r\n```python\r\nsigmoid_focal_loss_jit(\r\n            pred,\r\n            class_target,\r\n            alpha=,\r\n            gamma=,\r\n            reduction=\"sum\"\r\n        )\r\n```\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.202Z"},{"title":"visible","img":"","href":"ai/ai-1/4","des":"# pytorch 可视化\r\n\r\n## 图片可视化\r\n```python \r\nfrom matplotlib import pyplot as plt\r\nimage = $image.cpu().clone()  # detach().numpy() 这里的 $image 要换成自己的变量名\r\n# image = image.permute(1,2,0)    # 这个是可选的，主要是要将图片的维度调正为(w, h, c)的形式\r\nplt.imshow(image)  # 准备图片\r\nplt.show()  # 展示图片\r\n```\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.202Z"},{"title":"GraphCut","img":"../../../img/article/2022-03-22-16-52-40.png","href":"ai/ai-2/0","des":"# GraphCut\r\n\r\n## 信息\r\n\r\n文章标题：Interactive Graph Cuts for Optimal Boundary & Region Segmentation of Objects in N-D Images\r\n\r\n文章链接：[https://www.csd.uwo.ca/~yboykov/Papers/iccv01.pdf](https://www.csd.uwo.ca/~yboykov/Papers/iccv01.pdf)\r\n\r\n发表时间：2001-07\r\n\r\n\r\n## 背景\r\n\r\n## 创新点简介\r\n用户标记部分像素作为“目标”或“背景”，为图像分割提供硬约束。此外，利用图像的边缘信息和区域信息作为软约束。图割方法是一种全局最优的N维图像分割方法。Graph cuts是一种能量优化算法，应用于前背景分割。它把图像分割问题当作图的最小割（min cut）问题。\r\n![](../../../img/article/2022-03-22-16-52-40.png)\r\n\r\n## 详细内容\r\n![](../../../img/article/2022-03-22","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.202Z"},{"title":"DANet","img":"../../../img/article/2022-02-18-17-29-10.png","href":"ai/ai-2/1","des":"# DANet \r\n\r\n## 信息\r\n\r\n文章标题：Dual Attention Network for Scene Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/1809.02983](https://arxiv.org/abs/1809.02983)\r\n\r\n发表时间：2018-09\r\n\r\n\r\n## 创新点简介\r\n本文使用自注意力机制，在语义分割上加入了位置自注意力机制和通道自注意力机制，根据作者表述，位置自注意力机制将图片中相似的内容进行互相增强`【原文：any two positions with similar features can contribute mutual improvement regardless of their distance in spatial dimension】`，而通道自注意力机制则可以捕获任意通道之间的互相依赖关系。`【原文：we use the similar self-attention mechanism to capture the channel dependencies between ","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.202Z"},{"title":"loss函数","img":"","href":"ai/ai-0/2","des":"# Loss 函数\r\nloss 函数用来衡量结果和预期之间的差距，为梯度下降给定优化方向。\r\n\r\n## 如何设计\r\n一个好的loss函数，可以让任务更好更高效的训练，举一下几个例子。\r\n1. 正则项：在Loss函数中设计正则项，可以有效的防止过拟合现象。<br/> \r\n   $$Loss = loss(y,\\hat{y}) + ||w||_{p}$$\r\n\r\n2. Focal Loss: 通过设计平衡因子，完成正负样本均衡，以及偏向对困难样本的训练<br/> \r\n$$ L_{fl}=\\left\\{\r\n\\begin{array}{rcl}\r\n-\\alpha (1-y)^{\\gamma}log(y')      &      & \\text{y=1(T)}\\\\\r\n-(1-\\alpha )(y')^{ \\gamma }log(1-y')  &      & \\text{y=0(F)}\r\n\\end{array} \\right. $$\r\n\r\n\r\n    $\\alpha$表示了正负样本的均衡，如果$\\alpha$越大，则Loss对于正样本越敏感。\r\n    $\\gamma$表示了对错误分类的惩罚力度","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.201Z"},{"title":"nn","img":"","href":"ai/ai-1/0","des":"# Pytouch.nn 相关函数对照\r\n\r\n## nn.Embedding\r\n【功能】<br/>\r\n产生一组存储固定大小的词典的嵌入向量的查找表。\r\n【初始化】\r\n```py\r\nembed = torch.nn.Embedding(num_embeddings,embedding_dim)\r\n```\r\n> num_embeddings (python:int) – 词典的大小尺寸\r\n> embedding_dim (python:int) – 嵌入向量的维度，即用多少维来表示一个符号。\r\n\r\n有时在初始化时会被赋值会伴随着初始化过程。\r\n```py\r\nself.init_proposal_boxes = nn.Embedding(300, 4)\r\nnn.init.constant_(self.init_proposal_boxes.weight[:, :2], 0.5)\r\nnn.init.constant_(self.init_proposal_boxes.weight[:, 2:], 1.0)\r\n```\r\n\r\n【使用】<br />\r\n使用过程中，将`embed`直接当作向量来是使用","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.201Z"},{"title":"MatrixOpration","img":"","href":"ai/ai-1/1","des":"# 常用pytorch矩阵操作\r\n| 操作 | 指令 | 备注 |\r\n|-----|-----|-----|\r\n| 从list转变 | torch.cat($list) | 往往这类操作后面接列表生成式|\r\n| 获取邻域 |F.unfold( x, kernel_size=kernel_size, padding=padding, dilation=dilation ) | kernel_size领域大小，padding边距，dilation填充，padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2|\r\n| 邻域->图像 |F.fold( x, kernel_size=kernel_size, padding=padding, dilation=dilation ) | kernel_size领域大小，padding边距，dilation填充，padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2|\r\n|出现过的量|torch.uni","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:32:39.201Z"}]}