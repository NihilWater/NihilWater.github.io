{"articles":[{"title":"sparse_RCNN","img":"../../../img/article/2022-03-15-15-25-43.png","href":"ai/ai-3/2","des":"# Sparse RCNN\r\n\r\n## 基础信息\r\n\r\n论文题目：Sparse R-CNN: End-to-End Object Detection with Learnable Proposals\r\n\r\n论文链接：[https://arxiv.org/abs/2011.12450](https://arxiv.org/abs/2011.12450)\r\n\r\n发表时间：2020-11\r\n\r\n## 创新\r\n\r\n使用可学习的100-300个边框来取代RPN（区域建议网络），实现了一个完全稀疏的端到端目标检测网络。\r\n\r\n\r\n## 详情\r\n\r\n### 稀疏和密集\r\n![](../../../img/article/2022-03-15-15-25-43.png)\r\n\r\n作者指出以前的目标检测都是每个特征像素做的，采用了“anchor boxes”机制，这会有十分密集的目标框（HWk个）产生，Faster RCNN 使用NMS筛选值的计算分类和边框回归的建议框，让一个密集的检测变得稀疏起来，但他仍然不能算是一个完全稀疏的目标检测方法（图b）。而本文作者所提出的Sparse RCNN则使用学习来的","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.038Z"},{"title":"GraphCut","img":"../../../img/article/2022-03-22-16-52-40.png","href":"ai/ai-4/0","des":"# GraphCut\r\n\r\n## 基础信息\r\n\r\n文章标题：Interactive Graph Cuts for Optimal Boundary & Region Segmentation of Objects in N-D Images\r\n\r\n文章链接：[https://www.csd.uwo.ca/~yboykov/Papers/iccv01.pdf](https://www.csd.uwo.ca/~yboykov/Papers/iccv01.pdf)\r\n\r\n发表时间：2001-07\r\n\r\n\r\n## 背景\r\n\r\n## 创新点简介\r\n用户标记部分像素作为“目标”或“背景”，为图像分割提供硬约束。此外，利用图像的边缘信息和区域信息作为软约束。图割方法是一种全局最优的N维图像分割方法。Graph cuts是一种能量优化算法，应用于前背景分割。它把图像分割问题当作图的最小割（min cut）问题。\r\n![](../../../img/article/2022-03-22-16-52-40.png)\r\n\r\n## 详细内容\r\n【具体步骤】\r\n- 首先，需要用户明确指出少量背景像素B和前景目标","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.038Z"},{"title":"initialize","img":"../../../img/article/2021-11-08-20-06-46.png","href":"ai/ai-1/4","des":"# pytorch权重初始化\r\n## 张量生成\r\n【全零张量】\r\n```py\r\ntorch.zeros((a,b,...))\r\n```\r\n\r\n\r\n## xavier 初始化\r\npytorch提供了uniform和normal两种\r\n\r\n![](../../../img/article/2021-11-08-20-06-46.png)\r\n\r\n使用normalize 进行初始化，随着网络的加深，梯度会消失。\r\n假设 $y = ax+b =w1x1+ w2x2 + ... + wnxn + b$\r\n\r\n对于y取方差有 $var(y) = var(w1x1) + var(w2x1) + var(w2x1) + var(b) = var(y) = N * var(wi) * var(xi)$\r\n所以，kaiming_normal 在初始化的时候让w在的分布都除以了$\\frac{1}{\\sqrt n}$, 来使得通过了全连接层的输出是和X同分布的。\r\n\r\n## kaiming 初始化\r\n针对ReLu 激活函数，有一般的输出，会被变成0，为了保持方差不变，会采用kaiming激活函数。在初始化的时候","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.037Z"},{"title":"loss","img":"","href":"ai/ai-1/5","des":"# loss 函数\r\n\r\n## 二次损失函数\r\n\r\n## sigmoid_focal_loss_jit\r\n```python\r\nsigmoid_focal_loss_jit(\r\n            pred,\r\n            class_target,\r\n            alpha=,\r\n            gamma=,\r\n            reduction=\"sum\"\r\n        )\r\n```\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.037Z"},{"title":"visible","img":"","href":"ai/ai-1/6","des":"# pytorch 可视化\r\n\r\n## 图片可视化\r\n```python \r\nfrom matplotlib import pyplot as plt\r\nimage = $image.cpu().clone()  # detach().numpy() 这里的 $image 要换成自己的变量名\r\n# image = image.permute(1,2,0)    # 这个是可选的，主要是要将图片的维度调正为(w, h, c)的形式\r\nplt.imshow(image)  # 准备图片\r\nplt.show()  # 展示图片\r\n```\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.037Z"},{"title":"MatrixOpration","img":"","href":"ai/ai-1/3","des":"# 常用pytorch矩阵操作\r\n| 操作 | 指令 | 备注 |\r\n|-----|-----|-----|\r\n| 从list转变 | torch.cat($list) | 往往这类操作后面接列表生成式|\r\n| 获取邻域 |F.unfold( x, kernel_size=kernel_size, padding=padding, dilation=dilation ) | kernel_size领域大小，padding边距，dilation填充，padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2|\r\n| 邻域->图像 |F.fold( x, kernel_size=kernel_size, padding=padding, dilation=dilation ) | kernel_size领域大小，padding边距，dilation填充，padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2|\r\n|出现过的量|torch.uni","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.036Z"},{"title":"安装","img":"","href":"ai/ai-1/0","des":"# 安装\r\n\r\n## 版本匹配列表\r\n\r\n版本对照表：[https://pytorch.org/get-started/previous-versions/](https://pytorch.org/get-started/previous-versions/)\r\n\r\n\r\n下载链接：[https://download.pytorch.org/whl/torch_stable.html](https://download.pytorch.org/whl/torch_stable.html)\r\n\r\n\r\n|   pytorch   | torchvision |  torchaudio |\r\n| ----------- | ----------- | ----------- |\r\n|    1.9.0    |    0.10.0   |    0.9.0    |\r\n|    1.8.1    |    0.9.1    |    0.8.1    |\r\n|    1.8.0    |    0.9.0    |    0.8.0    |\r\n|    1.7.1    |    0.8.","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.035Z"},{"title":"nn","img":"","href":"ai/ai-1/1","des":"# Pytouch.nn 相关函数对照\r\n\r\n## nn.Embedding\r\n【功能】<br/>\r\n产生一组存储固定大小的词典的嵌入向量的查找表。\r\n【初始化】\r\n```py\r\nembed = torch.nn.Embedding(num_embeddings,embedding_dim)\r\n```\r\n> num_embeddings (python:int) – 词典的大小尺寸\r\n> embedding_dim (python:int) – 嵌入向量的维度，即用多少维来表示一个符号。\r\n\r\n有时在初始化时会被赋值会伴随着初始化过程。\r\n```py\r\nself.init_proposal_boxes = nn.Embedding(300, 4)\r\nnn.init.constant_(self.init_proposal_boxes.weight[:, :2], 0.5)\r\nnn.init.constant_(self.init_proposal_boxes.weight[:, 2:], 1.0)\r\n```\r\n\r\n【使用】<br />\r\n使用过程中，将`embed`直接当作向量来是使用","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.035Z"},{"title":"coco数据集","img":"","href":"ai/ai-0/0","des":"# coco 数据集介绍\r\n\r\nMS COCO的全称是Microsoft Common Objects in Context ，COCO数据集是微软构建的一个数据集，其中包含丰富的物体检测，分割和关键点数据。这个数据集以场景理解为目标，与PASCAL VOC数据集相比，COCO中的数据集从复杂的日常场景中截取，背景更为复杂，目标数量比较多且目标尺寸更小，因此在COCO数据集上的实现好的效果更为困难。到目前为止，拥有最大的图像分割数据集，一共存在80个标注类别，有超过33 万张图片，其中20 万张有标注，整个数据集中个体的数目超过150 万个。","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.034Z"},{"title":"regularization正则化 copy","img":"../../../img/article/2021-10-29-23-50-14.png","href":"ai/ai-0/1","des":"# 正则化\r\n## 定义\r\n&emsp;&emsp;正则化在深度学习的训练中，往往起到一个规范模型结构的作用，比如为了让模型防止发生过拟合，提高泛化能力，我们会通过加入正则项来完成对高次分量的抑制。其中防止过拟合也会被称为减小结构风险。\r\n\r\n![过拟合，正常，欠拟合效果](../../../img/article/2021-10-29-23-50-14.png)\r\n\r\n&emsp;&emsp;[维基百科](https://en.wikipedia.org/wiki/Regularization_(mathematics))中这么定义：在数学、统计学、金融、 计算机科学中，特别是在机器学习和逆问题中，正则化是添加信息以解决不适定问题或防止过度拟合的过程。正则化可以应用于不适定优化问题中的目标函数。正则化项或惩罚项对优化函数施加了成本，以使最优解唯一。\r\n\r\n\r\n## 范数\r\n&emsp;&emsp;范数的起源是用来比较两个向量之间的大小，比较标量的大小十分容易，比较张量就需要我们将张量以某种形式的计算，变成标量，从而进行比较，范数的作用就是这个可以完成向量到标量计算的函数。\r\n范数的一","commend":0,"watch":0,"evaluate":0,"date":"2022-04-11T02:24:39.034Z"}]}