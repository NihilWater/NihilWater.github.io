{"articles":[{"title":"DETR","img":"../../../img/article/2022-03-11-16-20-09.png","href":"ai/ai-7/0","des":"# DETR\r\n\r\n## 信息\r\n\r\n论文标题：End-to-End Object Detection with Transformers\r\n\r\n论文链接：[https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)\r\n\r\n发表时间：2020-05\r\n\r\n\r\n## 创新\r\nDETR提出使用transformer，学习固定个数目标编码作为解码器的Q，来去除非极大化抑制的影响。具体来说首先使用CNN提取特征，然后将特征输入transformer的编码层，得到解码器的K和V，之后传入解码器，结合目标编码，产生解码结果，后通过MLP，映射到每一个对象的类别和边界框。和Faster RCNN转化为Mask RCNN一样，加入了mask head的DETR实现了分割任务。\r\n\r\n![](../../../img/article/2022-03-11-16-20-09.png)\r\n\r\n## 详情\r\n![](../../../img/article/2022-03-11-16-05-44.png)\r\n\r\n使用DETR进行实例分","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.625Z"},{"title":"AssociativeEmbedding","img":"../../../img/article/2022-03-22-20-46-17.png","href":"ai/ai-5/6","des":"# Associative Embedding\r\n\r\n## 信息\r\n\r\n文章标题：Associative Embedding: End-to-End Learning for Joint Detection and Grouping\r\n\r\n文章链接：[https://proceedings.neurips.cc/paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html)\r\n\r\n发表时间：2017  (NIPS 2017)\r\n\r\n测试数据集： MPII 和 MS-COCO\r\n\r\n## 背景\r\n许多计算机视觉任务可以看作是联合的检测和分组，以关键点检测为例，都是检测较小的视觉单元（例如膝盖，手腕，头部），然后再并将它们分组到更大结构中。作者认为种方法可能是次优的, 因为检测和分组通常是紧密耦合的。\r\n\r\n## 创新点简介\r\n本文探讨了使","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.624Z"},{"title":"DiscriminativeLoss","img":"../../../img/article/2022-03-30-16-21-12.png","href":"ai/ai-5/7","des":"# Discriminative Loss\r\n\r\n## 信息\r\n\r\n文章标题：Semantic Instance Segmentation with a Discriminative Loss Function\r\n\r\n文章链接：[https://arxiv.org/abs/1708.02551](https://arxiv.org/abs/1708.02551)\r\n\r\n发表时间：2017-08 \r\n\r\n\r\n## 背景\r\n对于实例分方法，目前存在着两种主流方法，一种是自上而下的先获取边界框，后进行二分类的方法了；另一种是先进行语义分割，后进行聚类的方法，本文就是属于后者。\r\n\r\n## 创新点简介\r\n本文是第一个成功地使用基于距离度量学习原理的区别性损失来完成深度网络实例分割任务的。具体来说，本文设计了一种Loss函数，它将像素空间到高纬度空间（嵌入空间）的映射。使得同类（同实例）物体中的像素映射到高维空间后，得到的embedding vector之间的距离（L1、L2距离）相近，从而使用聚类的方式完成分割任务。\r\n\r\n## 详细内容\r\n\r\n**【 Loss 函数的三个约束】**\r\n\r\n【","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.624Z"},{"title":"PANet","img":"../../../img/article/2022-03-24-22-55-05.png","href":"ai/ai-5/8","des":"# PANet\r\n\r\n## 信息\r\n\r\n文章标题：Path Aggregation Network for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/1803.01534](https://arxiv.org/abs/1803.01534)\r\n\r\n发表时间：2018-03 (CVPR-2018)\r\n\r\n\r\n## 背景\r\nMask-RCNN的信息传播还不够充分。低层特征到高层特征的传递路径过长，FPN中每个proposal只负责金字塔特定的一层，掩码预测只基于单一视角。\r\n\r\n## 创新点简介\r\n- 自底向上的路径增强，为了缩短信息传播路径，同时利用低层特征的精准定位信息\r\n- 动态特征池化，每个proposal利用金字塔所有层的特征，为了避免proposal的随意分配\r\n- 全连接层融合，为了给掩码预测增加信息来源，文中的说法是capture diffrent view\r\n\r\n![](../../../img/article/2022-03-24-22-55-05.png)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.624Z"},{"title":"PANet2","img":"","href":"ai/ai-5/10","des":"# PANet2\r\n\r\n## 信息\r\n\r\n文章标题：PANet Few-Shot Image Semantic Segmentation with Prototype Alignment\r\n\r\n文章链接：\r\n\r\n发表时间：\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n少训练样本的分割\r\n\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.624Z"},{"title":"BlendMask","img":"../../../img/article/2022-02-25-15-11-58.png","href":"ai/ai-5/12","des":"# BlendMask\r\n\r\n## 信息\r\n\r\n文章标题：BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2001.0309](https://arxiv.org/abs/2001.0309)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 创新点简介\r\n本文使用提出了blender模型，将低层信息和高层信息融合，取得了更好的效果。其中高层信息会被制作成Attention map，而低层信息则包含更多的区分细节。轻量级模型在1080Ti上可达25FPS，用COCO数据集，mAP达34.2%。\r\n\r\n\r\n## 详细内容\r\n### 模型结构\r\n![](../../../img/article/2022-02-25-15-11-58.png)\r\n\r\n上文所说的低层信息，就是这里从骨干和FPN输出中提取出来的`Bases`，而所谓高层特征则是通过了一个个又通过了Tower之后又经过`Boxes Attns`模块的信息，他们通过Blender进行相乘，然后相加","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.624Z"},{"title":"基础","img":"../../../img/article/2021-11-03-13-35-03.png","href":"ai/ai-5/0","des":"# 基础\r\n\r\n![](../../../img/article/2021-11-03-13-35-03.png)\r\n\r\n## 实例分割和语义分割\r\n1. 能否完全使用语义分割？\r\n\r\n   不行，由于目标数目不固定，不能让一个实例就是一个类别。一般思路是先进行目标检测，后对检测狂内的物体进行语义分割，判断检测框内语义分割结果与哪个实例掩膜最接近就认为是哪实例。\r\n\r\n2. 存在的问题：两个实例重叠\r\n   \r\n   解决方案1：预测回归框，在回归框里进行二分类。\r\n   \r\n   解决方法2：预测中心，进行聚类。\r\n\r\n\r\n## 实例分割可以做的点\r\n> 现阶段语义分割的架构旨在优化分割结果的精确性和提高分割效率。\r\n> \r\n> 1) 小目标图像实例分割：存在分割准确率低、效果差，还不能完全满足实际应用的要求，存在明显的漏分割、错分割、分割边界模糊等问题。\r\n> \r\n> 2) 低质量图像实例分割：环境问题：雨天，大雾，夜间，水下环境。设备问题：曝光，移动，景深。\r\n> \r\n> 3) 轻量化网络架构的需求：在移动端、嵌入式设备的普及应用。\r\n> \r\n> 4) 遮挡问题：物品之间存在遮挡","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.623Z"},{"title":"InstanceFCN","img":"../../../img/article/2022-03-07-22-06-33.png","href":"ai/ai-5/2","des":"# InstanceFCN\r\n\r\n## 信息\r\n\r\n文章标题：Instance-sensitive Fully Convolutional Networks\r\n\r\n文章链接：[https://link.springer.com/chapter/10.1007/978-3-319-46466-4_32](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_32)\r\n\r\n发表时间：2016-09 (ECCV 2016)\r\n\r\n## 背景\r\n对于以往的图像分割模型，由于卷积具有<font color=\"red\">位置的不敏感性</font>（对于相同的事物，在图像中处于不同的位置，卷积核的输出相同），导致了当两个相似的事物靠近时很难通过卷积来加以区分。\r\n\r\n## 创新点简介\r\n本文使用全卷积神经网络构建端到端的实例分割模型，它只分割每个实例，没有对实例进行分类。基于语义分割的模型，只有一种语义信息，如果两个实例距离贴就无法区分个体。这是由于卷积具有位置不变性造成的，作者使用滑动窗口，将窗口划分为9个小格（编号为1-9），每","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.623Z"},{"title":"MaskRCNN","img":"../../../img/article/2021-10-30-13-42-24.png","href":"ai/ai-5/3","des":"# MaskRCNN\r\n\r\n## 信息\r\n\r\n文章标题：\r\n\r\n文章链接：[Mask_RCNN](https://arxiv.org/pdf/1703.06870)\r\n\r\n发表时间：2017-03\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\nMaskRCNN在FastRCNN的基础上加入了对于实例掩膜的预测分支，通过bounding box回归检测出每一个物品之后，再对回归框中的每一个像素进行分类，完成语义分割。这样的就实现了实例分割，即`目标检测+语义分割=实力分割`！\r\n\r\n## 详细内容\r\n\r\n### 实例分支训练\r\n训练时，通过当前得到的真实mask中的类别class_id，遍历所有的预测mask，找到class_id类别所对应的预测mask(前向传播中介绍过每个类别都有一个预测mask)，比较真实mask与预测mask每个像素点信息，用的是binary_cross_entropy二分类交叉熵损失函数\r\n![](../../../img/article/2021-10-30-13-42-24.png)\r\n\r\n**实例分割**\r\n![](../../../img/arti","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.623Z"},{"title":"SSIS Metric Learning","img":"../../../img/article/2022-02-25-15-11-58.png","href":"ai/ai-5/4","des":"# 【实例分割】Semantic Instance Segmentation via Deep Metric Learning\r\n\r\n## 信息\r\n文章标题 Semantic Instance Segmentation via Deep Metric Learning\r\n\r\n文章链接：[https://arxiv.org/abs/1703.10277](https://arxiv.org/abs/1703.10277)\r\n\r\n发表时间：2017-10\r\n\r\n## 创新点简介\r\n本文使用先计算出两个像素属于同一个目标的可能性后再聚类的方式，完成实例分割任务。`【论文原句】first computing how likely two pixels are to belong to the same object, and then by grouping similar pixels together`。具体来说论文使用全卷积的模型计算出相似度矩阵，然后通过“种子点”聚类相似像素。这些 “种子点” 是由一个全卷积网络训练出来的。\r\n\r\n\r\n## 详细内容\r\n### 模型结构\r\n![](..","commend":0,"watch":0,"evaluate":0,"date":"2022-03-30T09:09:38.623Z"}]}