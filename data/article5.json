{"articles":[{"title":"SETR","img":"../../../img/article/2022-03-11-14-59-06.png","href":"ai/ai-8/0","des":"# SETR\r\n\r\n## 基础信息\r\n\r\n论文题目：Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers\r\n\r\n文章链接：[https://arxiv.org/abs/2012.15840](https://arxiv.org/abs/2012.15840)\r\n\r\n发表时间：2020-12 (2021 CVPR)\r\n\r\n## 背景\r\n\r\n语义分割网络需要进行像素的分类，为例保证物体边缘像素被正确分类，需要很大的感受野支持，典型的语义分割Encoder-Decoder结构以多次下采样损失空间分辨率为代价来抽取局部/全局特征。网络Layer一旦固定,每一层的感受野是受限的,因此要获得更大范围的语义信息,理论上需要更大的感受野即更深的网络结构。\r\n\r\n如何既能够抽取全局的语义信息,又能尽量不损失分辨率,一直是语义分割的难点。\r\n\r\n## 创新点简介\r\nSETR使用transformer设计了一个端到端的语义分割网络，首先将原图切割为若干 16x16 个窗口，把其中的","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.492Z"},{"title":"基础","img":"../../../img/article/2022-02-18-11-31-12.png","href":"ai/ai-9/0","des":"# 弱监督实例分割\r\n\r\n## 基本问题\r\n为解决人工标注实例所消耗大量时间的问题，弱监督实例分割(WSIS)利用更加简单的标签，例如检测框，图片分类标签来进行实例分割。\r\n\r\n## 标签类别\r\n弱监督标签分类通常分为以下的4种，分别是图片分类标签，边界框，点标注和涂鸦标注。 其中标注成本最小的图片分类，它仅仅提供了一张图片中所出现物品的分类信息，也叫做图像级别的标注。\r\n\r\n![](../../../img/article/2022-02-18-11-31-12.png)\r\n\r\n\r\n## 两大问题\r\n弱监督实例分割不同于语义分割，它既要对每个像素进行分类，又要区分不同的同类个体。\r\n\r\n![](../../../img/article/2022-02-18-19-57-14.png)\r\n\r\n1. 像素分类问题：对于没一个像素，都需要知道其属于哪一个类别，一般会使用到类激活图的方式进行分类。\r\n2. 同类物体区分问题：对于同一种类的不同个体，实例分割需要他们进行区分。常见的区分方法包括边界框区分，预测中心区分。\r\n\r\n## 经典流程\r\n一个完整的弱监督分割方法主要包含三个流程\r\n1. ","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.492Z"},{"title":"PANet2","img":"","href":"ai/ai-5/12","des":"# PANet2\r\n\r\n## 基础信息\r\n\r\n文章标题：PANet Few-Shot Image Semantic Segmentation with Prototype Alignment\r\n\r\n文章链接：\r\n\r\n发表时间：\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n少训练样本的分割\r\n\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.490Z"},{"title":"BlendMask","img":"../../../img/article/2022-02-25-15-11-58.png","href":"ai/ai-5/13","des":"# BlendMask\r\n\r\n## 基础信息\r\n\r\n文章标题：BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2001.0309](https://arxiv.org/abs/2001.0309)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 创新点简介\r\n本文使用提出了blender模型，将低层信息和高层信息融合，取得了更好的效果。其中高层信息会被制作成Attention map，而低层信息则包含更多的区分细节。轻量级模型在1080Ti上可达25FPS，用COCO数据集，mAP达34.2%。\r\n\r\n\r\n## 详细内容\r\n### 模型结构\r\n![](../../../img/article/2022-02-25-15-11-58.png)\r\n\r\n上文所说的低层信息，就是这里从骨干和FPN输出中提取出来的`Bases`，而所谓高层特征则是通过了一个个又通过了Tower之后又经过`Boxes Attns`模块的信息，他们通过Blender进行相乘，然后","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.490Z"},{"title":"SPRNet","img":"","href":"ai/ai-5/14","des":"# SPRNet\r\n\r\n## 基础信息\r\n\r\n文章标题：SPRNet: Single Pixel Reconstruction for One-stage Instance Segmentation\r\n\r\n文章链接：\r\n\r\n发表时间：\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.490Z"},{"title":"CondInst","img":"../../../img/article/2021-12-01-23-34-22.png","href":"ai/ai-5/15","des":"# CondInst\r\n\r\n## 基础信息\r\n\r\n文章标题：Conditional Convolutions for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2003.05664](https://arxiv.org/abs/2003.05664)\r\n\r\n发表时间：2020-03\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\nCondInst 在全卷积网络FCOS的基础上通过引入条件卷积，完成了对于实例分割任务的实现。Condinst completes the task of instance segmentation by introducing conditional convolution on the basis of full convolution network fcos.\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n![](../../../img/article/2021-12-01-23-34-22.png)\r\n\r\n### 条件卷积细节\r\n在计算边框和中心度分支的同级，引入条件卷积分支（一","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.490Z"},{"title":"BPR微调框","img":"../../../img/article/2022-03-22-16-30-46.png","href":"ai/ai-5/17","des":"# BPR微调框\r\n\r\n## 基础信息\r\n\r\n文章标题：Look Closer to Segment Better: Boundary Patch Refinement for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2104.05239](https://arxiv.org/abs/2104.05239)\r\n\r\n发表时间：2021-04\r\n\r\n\r\n## 背景\r\n\r\n在实例分割任务中，由于特征图的空间分辨率低，以及边界像素比例极低造成的不平衡问题，使得预测的实例掩码的边界通常是不精确的。\r\n\r\n## 创新点简介\r\n![](../../../img/article/2022-03-22-16-30-46.png)\r\n\r\n本文提出一个后处理 refinement 框架：BPR，用来改善基于任何实例分割模型结果的边界质量。BPR 在 Cityscapes 基准上比 Mask R-CNN 基线有明显的改进，特别是在边界感知指标上。此外，通过将 BPR 框架应用于 PolyTransform + SegFix 基线，在 Citys","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.490Z"},{"title":"MaskRCNN","img":"../../../img/article/2021-10-30-13-42-24.png","href":"ai/ai-5/5","des":"# MaskRCNN\r\n\r\n## 基础信息\r\n\r\n文章标题：MaskRCNN\r\n\r\n文章链接：[Mask_RCNN](https://arxiv.org/pdf/1703.06870)\r\n\r\n发表时间：2017-03\r\n\r\n## 背景\r\n\r\n## 创新点简介\r\nMaskRCNN在FastRCNN的基础上加入了对于实例掩膜的预测分支，通过bounding box回归检测出每一个物品之后，再对回归框中的每一个像素进行分类，完成语义分割。这样的就实现了实例分割，即`目标检测+语义分割=实力分割`！\r\n\r\n## 详细内容\r\n\r\n### 实例分支训练\r\n训练时，通过当前得到的真实mask中的类别class_id，遍历所有的预测mask，找到class_id类别所对应的预测mask(前向传播中介绍过每个类别都有一个预测mask)，比较真实mask与预测mask每个像素点信息，用的是binary_cross_entropy二分类交叉熵损失函数\r\n![](../../../img/article/2021-10-30-13-42-24.png)\r\n\r\n**实例分割**\r\n![](../../../im","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.489Z"},{"title":"SSIS Metric Learning","img":"../../../img/article/2022-02-25-15-11-58.png","href":"ai/ai-5/6","des":"# 【实例分割】Semantic Instance Segmentation via Deep Metric Learning\r\n\r\n## 基础信息\r\n文章标题 Semantic Instance Segmentation via Deep Metric Learning\r\n\r\n文章链接：[https://arxiv.org/abs/1703.10277](https://arxiv.org/abs/1703.10277)\r\n\r\n发表时间：2017-03-30\r\n\r\n## 创新点简介\r\n本文使用先计算出两个像素属于同一个目标的可能性后再聚类的方式，完成实例分割任务。`【论文原句】first computing how likely two pixels are to belong to the same object, and then by grouping similar pixels together`。具体来说论文使用全卷积的模型计算出相似度矩阵，然后通过“种子点”聚类相似像素。这些 “种子点” 是由一个全卷积网络训练出来的。\r\n\r\n\r\n## 详细内容\r\n### 模型结构\r\n!","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.489Z"},{"title":"AssociativeEmbedding","img":"../../../img/article/2022-03-22-20-46-17.png","href":"ai/ai-5/8","des":"# Associative Embedding\r\n\r\n## 基础信息\r\n\r\n文章标题：Associative Embedding: End-to-End Learning for Joint Detection and Grouping\r\n\r\n文章链接：[https://proceedings.neurips.cc/paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/8edd72158ccd2a879f79cb2538568fdc-Abstract.html)\r\n\r\n发表时间：2017  (NIPS 2017)\r\n\r\n测试数据集： MPII 和 MS-COCO\r\n\r\n## 背景\r\n许多计算机视觉任务可以看作是联合的检测和分组，以关键点检测为例，都是检测较小的视觉单元（例如膝盖，手腕，头部），然后再并将它们分组到更大结构中。作者认为种方法可能是次优的, 因为检测和分组通常是紧密耦合的。\r\n\r\n## 创新点简介\r\n本文探讨","commend":0,"watch":0,"evaluate":0,"date":"2022-04-07T14:56:06.489Z"}]}