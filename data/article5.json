{"articles":[{"title":"BoxInst变量","img":"../../../img/article/2021-11-01-10-35-26.png","href":"ai/ai-9/5","des":"# BoxInst 变量\r\n本文简单介绍BoxInst 模型中所使用到的关键变量\r\n\r\n## 基础信息\r\n\r\n论文标题: BoxInst: High-Performance Instance Segmentation with Box Annotations\r\n\r\n论文链接：[https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html](https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html)\r\n\r\n发布时间: 2020-12 (CVPR 2021)\r\n\r\n## 创新点总结\r\n提出了一种高性能、仅使用边界框注释进行训练的任务级","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.379Z"},{"title":"MRP","img":"","href":"ai/ai-9/2","des":"# MRP\r\n\r\n## 基础信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation using Class Peak Response\r\n\r\n文章链接：[https://arxiv.org/pdf/1804.00880.pdf](https://arxiv.org/pdf/1804.00880.pdf)\r\n\r\n发表时间：2018-04\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n作者观察到类响应图的峰值大概率对应着一个真实的实例，先算出峰值位置，然后通过反向传播，获取峰值响应图（MRP）\r\n\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.378Z"},{"title":"IRNet","img":"../../../img/article/2022-03-24-11-04-21.png","href":"ai/ai-9/3","des":"# IRNet\r\n\r\n## 基础信息\r\n\r\n文章标题：Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations\r\n\r\n文章链接：[http://arxiv.org/pdf/1904.05044](http://arxiv.org/pdf/1904.05044)\r\n\r\n发表时间：2019-04 (CPVR 2019)\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n\r\n![](../../../img/article/2022-03-24-11-04-21.png)\r\n\r\n本文使用全集标记，类激活图完成了实例分割任务。为解决类激活图无法区分实例，使用了pairwise semantic affinitie（成对语义相似关系）和lass-agnostic instance map (无类别实例映射)。(类不可知实例映射是一个粗糙的实例分割掩码，没有类标签，也没有精确的边界。另一方面，一对像素之间的语义亲和力是它们之间的类等价性的置信度。)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.378Z"},{"title":"Can Vision Transformers Learn without Natural Images","img":"","href":"ai/ai-6/1","des":"# Vision Transformers Learn without Natural Images\r\n\r\n\r\n## 摘要\r\n\r\n【函数驱动的监督学习】使用了 FDSL,(Formula-Driven Supervised Learning)函数驱动的监督学习。先前的FDSL主要是产生了形状不同的形状的图形的物体，进行训练。在本文中作者又引入了颜色和斑块来进行训练。\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.377Z"},{"title":"DETR","img":"../../../img/article/2022-03-11-16-20-09.png","href":"ai/ai-7/0","des":"# DETR\r\n\r\n## 基础信息\r\n\r\n论文标题：End-to-End Object Detection with Transformers\r\n\r\n论文链接：[https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)\r\n\r\n发表时间：2020-05\r\n\r\n\r\n## 创新\r\nDETR提出使用transformer，学习固定个数目标编码作为解码器的Q，来去除非极大化抑制的影响。具体来说首先使用CNN提取特征，然后将特征输入transformer的编码层，得到解码器的K和V，之后传入解码器，结合目标编码，产生解码结果，后通过MLP，映射到每一个对象的类别和边界框。和Faster RCNN转化为Mask RCNN一样，加入了mask head的DETR实现了分割任务。\r\n\r\n![](../../../img/article/2022-03-11-16-20-09.png)\r\n\r\n## 详情\r\n![](../../../img/article/2022-03-11-16-05-44.png)\r\n\r\n使用DETR进行实","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.377Z"},{"title":"Queryinst","img":"","href":"ai/ai-7/1","des":"","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.377Z"},{"title":"SOLQ","img":"../../../img/article/2022-03-12-13-59-28.png","href":"ai/ai-7/2","des":"# SOLQ\r\n\r\n## 基础信息\r\n\r\n论文题目：SOLQ: Segmenting Objects by Learning Queries\r\n\r\n论文链接：[https://arxiv.org/abs/2106.02351](https://arxiv.org/abs/2106.02351)\r\n\r\n发表时间：2021-06\r\n\r\n## 创新\r\n\r\nSOLQ基于近期所提出的 DETR的实例分割的端到端框架，通过学习统一的查询来分割目标。不同于DETR通过引入类似于MaskRCNN中的Mask分支完成分割，SOLQ中的每个查询代表一个对象，里面包含了所有的class, location 和 mask信息。\r\n\r\n![](../../../img/article/2022-03-12-13-59-28.png)\r\n\r\n如上图所示，对于DETR，它通过设置一个长采样卷积结构完成对于实例mask的获取\r\n\r\n![](../../../img/article/2022-03-12-13-58-55.png)\r\n\r\n![](../../../img/article/2022-03-12-14-03","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.377Z"},{"title":"SETR","img":"../../../img/article/2022-03-11-14-59-06.png","href":"ai/ai-8/0","des":"# SETR\r\n\r\n## 基础信息\r\n\r\n论文题目：Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers\r\n\r\n文章链接：[https://arxiv.org/abs/2012.15840](https://arxiv.org/abs/2012.15840)\r\n\r\n发表时间：2020-12 (2021 CVPR)\r\n\r\n## 背景\r\n\r\n语义分割网络需要进行像素的分类，为例保证物体边缘像素被正确分类，需要很大的感受野支持，典型的语义分割Encoder-Decoder结构以多次下采样损失空间分辨率为代价来抽取局部/全局特征。网络Layer一旦固定,每一层的感受野是受限的,因此要获得更大范围的语义信息,理论上需要更大的感受野即更深的网络结构。\r\n\r\n如何既能够抽取全局的语义信息,又能尽量不损失分辨率,一直是语义分割的难点。\r\n\r\n## 创新点简介\r\nSETR使用transformer设计了一个端到端的语义分割网络，首先将原图切割为若干 16x16 个窗口，把其中的","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.377Z"},{"title":"基础","img":"../../../img/article/2022-02-18-11-31-12.png","href":"ai/ai-9/0","des":"# 弱监督实例分割\r\n\r\n## 基本问题\r\n为解决人工标注实例所消耗大量时间的问题，弱监督实例分割(WSIS)利用更加简单的标签，例如检测框，图片分类标签来进行实例分割。\r\n\r\n## 标签类别\r\n弱监督标签分类通常分为以下的4种，分别是图片分类标签，边界框，点标注和涂鸦标注。 其中标注成本最小的图片分类，它仅仅提供了一张图片中所出现物品的分类信息，也叫做图像级别的标注。\r\n\r\n![](../../../img/article/2022-02-18-11-31-12.png)\r\n\r\n\r\n## 两大问题\r\n弱监督实例分割不同于语义分割，它既要对每个像素进行分类，又要区分不同的同类个体。\r\n\r\n![](../../../img/article/2022-02-18-19-57-14.png)\r\n\r\n1. 像素分类问题：对于没一个像素，都需要知道其属于哪一个类别，一般会使用到类激活图的方式进行分类。\r\n2. 同类物体区分问题：对于同一种类的不同个体，实例分割需要他们进行区分。常见的区分方法包括边界框区分，预测中心区分。\r\n\r\n## 经典流程\r\n一个完整的弱监督分割方法主要包含三个流程\r\n1. ","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.377Z"},{"title":"PANet","img":"../../../img/article/2022-03-24-22-55-05.png","href":"ai/ai-5/10","des":"# PANet\r\n\r\n## 基础信息\r\n\r\n文章标题：Path Aggregation Network for Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/1803.01534](https://arxiv.org/abs/1803.01534)\r\n\r\n发表时间：2018-03 (CVPR-2018)\r\n\r\n\r\n## 背景\r\nMask-RCNN的信息传播还不够充分。低层特征到高层特征的传递路径过长，FPN中每个proposal只负责金字塔特定的一层，掩码预测只基于单一视角。\r\n\r\n## 创新点简介\r\n- 自底向上的路径增强，为了缩短信息传播路径，同时利用低层特征的精准定位信息\r\n- 动态特征池化，每个proposal利用金字塔所有层的特征，为了避免proposal的随意分配\r\n- 全连接层融合，为了给掩码预测增加信息来源，文中的说法是capture diffrent view\r\n\r\n![](../../../img/article/2022-03-24-22-55-05.png)\r\n\r\n## 详细内容\r\n\r\n### 模型结构","commend":0,"watch":0,"evaluate":0,"date":"2022-04-13T16:01:06.375Z"}]}