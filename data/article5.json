{"articles":[{"title":"introduction","img":"","href":"ai/ai-12/0","des":"# 图卷积神经网络\r\n## 意义\r\n使用神经网络来表达一张图上的信息。图相较于其他的数据结构，存在更加明显的结构特性。一张图的信息包含有4个方面，顶点的信息，边的信息，图整体的信息，图的连接信息。如今，大部分GNN在做的事情就是以一张图片的这些信息作为输入，得到一张输出图，输出图的结构信息与原图一样，但是顶点信息，边信息，整张图的信息表达会发生改变。\r\n\r\n## 信息的表达\r\n对于顶点信息，我们可以使用一个向量来进行表示。\r\n\r\n对于每一条边，我们同样可以使用一个向量来表示。\r\n对于全局信息，我们可以使用所有点的均值与所有边的均值进行表示，也可以使用一个和全部节点相连接的伪节点进行信息的表达。\r\n对于连接性，我们可以使用邻接表或者邻接矩阵来表示。\r\n\r\n## 案例说明\r\n【顶点分类问题】：已知一张图上有若干节点，需要对这些节点进行分类。\r\n① 最简单的方式，可能我们已经有了节点的向量表达，所以只需要对每个节点做一次全连接+softmax之类的分类网络就可以表示信息了。\r\n② 信息转化，假设顶点没有合理的向量表达，或者表达能力较弱，我们可以用边的","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.131Z"},{"title":"GAP和CAM","img":"../../../img/article/2021-12-04-12-33-29.png","href":"ai/ai-10/1","des":"# 全局平均池化 与 类激活图\r\n\r\n## 基础信息\r\n\r\n类激活图:[https:://arxiv.org/pdf/1512.04150.pdf](https:://arxiv.org/pdf/1512.04150.pdf)\r\n\r\n文章链接：[https:://arxiv.org/pdf/1512.04150.pdf](https:://arxiv.org/pdf/1512.04150.pdf)\r\n\r\n发表时间：2015-12\r\n\r\n\r\n## 创新点简介\r\n全连接的出现（左图），让每一个特征图节点和最终的输出节点产生联系，这种联系和注意力机制一样，会产生空间信息的丢失，于是便提出了全局平均池化的概念，让模型输出某个类的概率之和某一层特征图有关。（使每一层特征输出的均值作为最后结果）。\r\n\r\n具体来说，CAM 通过将预训练的分类网络的全连接层，替换成了输出通道为类别数的卷积网络，对每个卷积网络的输出做全局平均池化，得到一个输出值，在这一组输出值上做softmax得到最终结果进行训练。\r\n\r\n![](../../../img/article/2021-12-04-12-33-29.png","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.130Z"},{"title":"CRF-RandWalk","img":"../../../img/article/2021-12-04-13-01-08.png","href":"ai/ai-10/2","des":"# CRF-RandWalk\r\n\r\n## 背景描述\r\n上文说到CAM方法，是一种在分类网络基础上替换网络的全连接层为，卷积+全局平均池化。由于对于一个目标是否属于一个类别来说，网络只需关注最有特点的地方，而不能完全覆盖一个目标。弱监督语义分割试图从CAM中得到掩码就需要让其关注整个目标，于是概均匀化的思想被提出。\r\n\r\n## 概率均匀化\r\n【本质】：设计一种概率转移方法，将图像中的密集概率向着整个物品进行扩散。也就是说通过计算两个特征像素之间的相似性，如果相似的话，就让当前像素上的概率和这个像素的概率进行均摊。\r\n\r\n## 条件随机场\r\n![](../../../img/article/2021-12-04-13-01-08.png)\r\n\r\n条件随机场通过“势函数”的引入，将初始的概率图进行转化。\r\n势函数包含了图片的像素色彩和位置信息\r\n\r\n## PCM\r\n![](../../../img/article/2021-12-04-13-18-36.png)\r\n\r\n图片来源于[https://arxiv.org/pdf/2004.04581v1](https://arxiv.org/pd","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.130Z"},{"title":"IRNet","img":"../../../img/article/2022-03-24-11-04-21.png","href":"ai/ai-9/3","des":"# IRNet\r\n\r\n## 基础信息\r\n\r\n文章标题：Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations\r\n\r\n文章链接：[http://arxiv.org/pdf/1904.05044](http://arxiv.org/pdf/1904.05044)\r\n\r\n发表时间：2019-04 (CPVR 2019)\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n\r\n![](../../../img/article/2022-03-24-11-04-21.png)\r\n\r\n本文使用全集标记，类激活图完成了实例分割任务。为解决类激活图无法区分实例，使用了pairwise semantic affinitie（成对语义相似关系）和lass-agnostic instance map (无类别实例映射)。(类不可知实例映射是一个粗糙的实例分割掩码，没有类标签，也没有精确的边界。另一方面，一对像素之间的语义亲和力是它们之间的类等价性的置信度。)\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.129Z"},{"title":"CommunityLearning","img":"../../../img/article/2022-04-04-15-34-56.png","href":"ai/ai-9/4","des":"# CommunityLearning\r\n\r\n## 基础信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation by Deep Community Learning\r\n\r\n文章链接：[https://arxiv.org/pdf/2001.11207.pdf](https://arxiv.org/pdf/2001.11207.pdf)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 背景\r\n对于弱监督的实例分割，简单的结合检测和分割网络的一个最关键的限制是，学习到的模型往往关注对象的小区域，无法恢复目标对象的缺失部分。这在一定程度上是因为**分割网络依赖于噪声检测结果，而没有适当的交互作用**，迭代标签细化过程的好处往往在早期阶段就饱和了。而两个模块输出之间的强相关性。\r\n\r\n## 创新点简介\r\n作者提出将目标检测，伪标签生成，实例分割等组件构造成一个循环链。该链有助于各个模块之间的交互，从而提取有用的信息。\r\n(社区学习， community learning)这篇文章通过训练多个子模型用于多个子任务，end-to-end trainabl","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.129Z"},{"title":"BoxInst变量","img":"../../../img/article/2021-11-01-10-35-26.png","href":"ai/ai-9/5","des":"# BoxInst 变量\r\n本文简单介绍BoxInst 模型中所使用到的关键变量\r\n\r\n## 基础信息\r\n\r\n论文标题: BoxInst: High-Performance Instance Segmentation with Box Annotations\r\n\r\n论文链接：[https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html](https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html)\r\n\r\n发布时间: 2020-12 (CVPR 2021)\r\n\r\n## 创新点总结\r\n提出了一种高性能、仅使用边界框注释进行训练的任务级","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.129Z"},{"title":"基础","img":"../../../img/article/2022-02-18-11-31-12.png","href":"ai/ai-9/0","des":"# 弱监督实例分割\r\n\r\n## 基本问题\r\n为解决人工标注实例所消耗大量时间的问题，弱监督实例分割(WSIS)利用更加简单的标签，例如检测框，图片分类标签来进行实例分割。\r\n\r\n## 标签类别\r\n弱监督标签分类通常分为以下的4种，分别是图片分类标签，边界框，点标注和涂鸦标注。 其中标注成本最小的图片分类，它仅仅提供了一张图片中所出现物品的分类信息，也叫做图像级别的标注。\r\n\r\n![](../../../img/article/2022-02-18-11-31-12.png)\r\n\r\n\r\n## 两大问题\r\n弱监督实例分割不同于语义分割，它既要对每个像素进行分类，又要区分不同的同类个体。\r\n\r\n![](../../../img/article/2022-02-18-19-57-14.png)\r\n\r\n1. 像素分类问题：对于没一个像素，都需要知道其属于哪一个类别，一般会使用到类激活图的方式进行分类。\r\n2. 同类物体区分问题：对于同一种类的不同个体，实例分割需要他们进行区分。常见的区分方法包括边界框区分，预测中心区分。\r\n\r\n## 经典流程\r\n一个完整的弱监督分割方法主要包含三个流程\r\n1. ","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.128Z"},{"title":"MRP","img":"","href":"ai/ai-9/2","des":"# MRP\r\n\r\n## 基础信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation using Class Peak Response\r\n\r\n文章链接：[https://arxiv.org/pdf/1804.00880.pdf](https://arxiv.org/pdf/1804.00880.pdf)\r\n\r\n发表时间：2018-04\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n作者观察到类响应图的峰值大概率对应着一个真实的实例，先算出峰值位置，然后通过反向传播，获取峰值响应图（MRP）\r\n\r\n\r\n## 详细内容\r\n\r\n### 模型结构\r\n\r\n\r\n## 引用","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.128Z"},{"title":"Can Vision Transformers Learn without Natural Images","img":"","href":"ai/ai-6/1","des":"# Vision Transformers Learn without Natural Images\r\n\r\n\r\n## 摘要\r\n\r\n【函数驱动的监督学习】使用了 FDSL,(Formula-Driven Supervised Learning)函数驱动的监督学习。先前的FDSL主要是产生了形状不同的形状的图形的物体，进行训练。在本文中作者又引入了颜色和斑块来进行训练。\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.127Z"},{"title":"DETR","img":"../../../img/article/2022-03-11-16-20-09.png","href":"ai/ai-7/0","des":"# DETR\r\n\r\n## 基础信息\r\n\r\n论文标题：End-to-End Object Detection with Transformers\r\n\r\n论文链接：[https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)\r\n\r\n发表时间：2020-05\r\n\r\n\r\n## 创新\r\nDETR提出使用transformer，学习固定个数目标编码作为解码器的Q，来去除非极大化抑制的影响。具体来说首先使用CNN提取特征，然后将特征输入transformer的编码层，得到解码器的K和V，之后传入解码器，结合目标编码，产生解码结果，后通过MLP，映射到每一个对象的类别和边界框。和Faster RCNN转化为Mask RCNN一样，加入了mask head的DETR实现了分割任务。\r\n\r\n![](../../../img/article/2022-03-11-16-20-09.png)\r\n\r\n## 详情\r\n![](../../../img/article/2022-03-11-16-05-44.png)\r\n\r\n使用DETR进行实","commend":0,"watch":0,"evaluate":0,"date":"2022-04-16T15:22:36.127Z"}]}