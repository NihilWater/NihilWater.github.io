{"articles":[{"title":"BAP_NAL","img":"../../../img/article/2021-11-03-21-39-58.png","href":"ai/ai-10/4","des":"# BAP边界感知池化和NAL感知损失\r\n\r\n## 基础信息\r\n\r\n文章标题：Background-Aware Pooling and Noise-Aware Loss forWeakly-Supervised Semantic Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2104.00905](https://arxiv.org/abs/2104.00905)\r\n\r\n发表时间：2021-04-02 (CVPR 2021)\r\n\r\n\r\n## 背景\r\n在使用边界框注释解决了弱监督语义分割（WSSS）的领域中，没有指定对象边界，因此很难训练卷积神经网络 (CNN) 进行语义分割。作者发现模型对边界框内外背景区域的感知具有相似性，这可以用来区分对象边界框内的前景和背景区域。\r\n\r\n## 创新点简介\r\n弱监督语义分割中的背景感知池化和噪声感知损失\r\n\r\n① 提出了BAP（背景感知池）方法，能够在边界框内分辨出前景和背景。具体做法是特征图上，利用边界框外的背景，计算出背景的特征表达。得到背景表达后，可以和边框内特征做相似度，对边界框内的背景和前景进行分割","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.841Z"},{"title":"【样本间信息学习】RCA","img":"../../../img/article/2022-04-12-16-49-56.png","href":"ai/ai-10/5","des":"# 【样本间信息学习】RCA\r\n\r\n## 基础信息\r\n\r\n文章标题：Regional Semantic Contrast and Aggregation for Weakly Supervised Semantic Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2203.09653](https://arxiv.org/abs/2203.09653)\r\n\r\n发表时间：2022-03-22\r\n\r\n\r\n## 背景\r\n\r\n从类别标签中学习语义分割的挑战在于很难从稀疏的类别标签中推断出目标密集的区域掩码。目前这方面的研究都只尝试在一个样本上或者一个样本组中进行，这严重限制了语义分割获取完整的注意力图。\r\n\r\n> Learning semantic segmentation from weakly-labeled (e.g., image tags only) data is challenging since it is hard to infer dense object regions from sparse semantic tags. Desp","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.841Z"},{"title":"PrototypicalNet","img":"","href":"ai/ai-11/0","des":"# PrototypicalNet\r\n\r\n## 基础信息\r\n\r\n文章标题：Prototypical Networks for Few-shot Learning\r\n\r\n文章链接：[https://arxiv.org/abs/1703.05175](https://arxiv.org/abs/1703.05175)\r\n\r\n发表时间：2017-03\r\n\r\n\r\n## 背景\r\n【度量学习】\r\n\r\n是一种学习两个样本（特征）之间相似性的学习方法。常见的度量有欧式距离、等。以上所提到的度量方法都是不可学习的，度量学习则使用神经网络来训练一个度量函数，这样做可以**对长度不同的片段进行比较**，也可以通过维度扩展的方式，来**寻找更深层次的相似性关系**。\r\n\r\n【度量空间】\r\n\r\n是指度量函数的集合\r\n\r\n【小样本学习】\r\n\r\n通过已经训练好的模型，在其基础之上加入新的分类，并且只有少量样本。在次基础上进行训练，使网络可以泛化到这些样本上。由于样本量很少，在新的类上很容易出先<font color=\"red\">过拟合的现象。</font>\r\n\r\n## 创新点简介\r\n本文使用原型网络`Prototy","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.841Z"},{"title":"introduction","img":"","href":"ai/ai-12/0","des":"# 图卷积神经网络\r\n## 意义\r\n使用神经网络来表达一张图上的信息。图相较于其他的数据结构，存在更加明显的结构特性。一张图的信息包含有4个方面，顶点的信息，边的信息，图整体的信息，图的连接信息。如今，大部分GNN在做的事情就是以一张图片的这些信息作为输入，得到一张输出图，输出图的结构信息与原图一样，但是顶点信息，边信息，整张图的信息表达会发生改变。\r\n\r\n## 信息的表达\r\n对于顶点信息，我们可以使用一个向量来进行表示。\r\n\r\n对于每一条边，我们同样可以使用一个向量来表示。\r\n对于全局信息，我们可以使用所有点的均值与所有边的均值进行表示，也可以使用一个和全部节点相连接的伪节点进行信息的表达。\r\n对于连接性，我们可以使用邻接表或者邻接矩阵来表示。\r\n\r\n## 案例说明\r\n【顶点分类问题】：已知一张图上有若干节点，需要对这些节点进行分类。\r\n① 最简单的方式，可能我们已经有了节点的向量表达，所以只需要对每个节点做一次全连接+softmax之类的分类网络就可以表示信息了。\r\n② 信息转化，假设顶点没有合理的向量表达，或者表达能力较弱，我们可以用边的","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.841Z"},{"title":"coco数据集","img":"","href":"ai/ai-0/0","des":"# coco 数据集介绍\r\n\r\nMS COCO的全称是Microsoft Common Objects in Context ，COCO数据集是微软构建的一个数据集，其中包含丰富的物体检测，分割和关键点数据。这个数据集以场景理解为目标，与PASCAL VOC数据集相比，COCO中的数据集从复杂的日常场景中截取，背景更为复杂，目标数量比较多且目标尺寸更小，因此在COCO数据集上的实现好的效果更为困难。到目前为止，拥有最大的图像分割数据集，一共存在80个标注类别，有超过33 万张图片，其中20 万张有标注，整个数据集中个体的数目超过150 万个。","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.825Z"},{"title":"regularization正则化 copy","img":"../../../img/article/2021-10-29-23-50-14.png","href":"ai/ai-0/1","des":"# 正则化\r\n## 定义\r\n&emsp;&emsp;正则化在深度学习的训练中，往往起到一个规范模型结构的作用，比如为了让模型防止发生过拟合，提高泛化能力，我们会通过加入正则项来完成对高次分量的抑制。其中防止过拟合也会被称为减小结构风险。\r\n\r\n![过拟合，正常，欠拟合效果](../../../img/article/2021-10-29-23-50-14.png)\r\n\r\n&emsp;&emsp;[维基百科](https://en.wikipedia.org/wiki/Regularization_(mathematics))中这么定义：在数学、统计学、金融、 计算机科学中，特别是在机器学习和逆问题中，正则化是添加信息以解决不适定问题或防止过度拟合的过程。正则化可以应用于不适定优化问题中的目标函数。正则化项或惩罚项对优化函数施加了成本，以使最优解唯一。\r\n\r\n\r\n## 范数\r\n&emsp;&emsp;范数的起源是用来比较两个向量之间的大小，比较标量的大小十分容易，比较张量就需要我们将张量以某种形式的计算，变成标量，从而进行比较，范数的作用就是这个可以完成向量到标量计算的函数。\r\n范数的一","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.825Z"},{"title":"loss函数","img":"","href":"ai/ai-0/2","des":"# Loss 函数\r\nloss 函数用来衡量结果和预期之间的差距，为梯度下降给定优化方向。\r\n\r\n## 如何设计\r\n一个好的loss函数，可以让任务更好更高效的训练，举一下几个例子。\r\n1. 正则项：在Loss函数中设计正则项，可以有效的防止过拟合现象。<br/> \r\n   $$Loss = loss(y,\\hat{y}) + ||w||_{p}$$\r\n\r\n2. Focal Loss: 通过设计平衡因子，完成正负样本均衡，以及偏向对困难样本的训练<br/> \r\n$$ L_{fl}=\\left\\{\r\n\\begin{array}{rcl}\r\n-\\alpha (1-y)^{\\gamma}log(y')      &      & \\text{y=1(T)}\\\\\r\n-(1-\\alpha )(y')^{ \\gamma }log(1-y')  &      & \\text{y=0(F)}\r\n\\end{array} \\right. $$\r\n\r\n\r\n> $\\alpha$表示了正负样本的均衡，如果$\\alpha$越大，则Loss对于正样本越敏感。\r\n> \r\n> $\\gamma$表示了对错误分类的惩罚力度","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.825Z"},{"title":"安装","img":"","href":"ai/ai-1/0","des":"# 安装\r\n\r\n## 版本匹配列表\r\n\r\n版本对照表：[https://pytorch.org/get-started/previous-versions/](https://pytorch.org/get-started/previous-versions/)\r\n\r\n\r\n下载链接：[https://download.pytorch.org/whl/torch_stable.html](https://download.pytorch.org/whl/torch_stable.html)\r\n\r\n\r\n| pytorch | torchvision | torchaudio |\r\n| ------- | ----------- | ---------- |\r\n| 1.10.1  | 0.11.2      | 1.10.1     |\r\n| 1.9.0   | 0.10.0      | 0.9.0      |\r\n| 1.8.1   | 0.9.1       | 0.8.1      |\r\n| 1.8.0   | 0.9.0       | 0.8.0      |\r\n| 1.7.1 ","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.825Z"},{"title":"nn","img":"","href":"ai/ai-1/1","des":"# Pytouch.nn 相关函数对照\r\n\r\n## nn.Embedding\r\n【功能】<br/>\r\n产生一组存储固定大小的词典的嵌入向量的查找表。\r\n【初始化】\r\n```py\r\nembed = torch.nn.Embedding(num_embeddings,embedding_dim)\r\n```\r\n> num_embeddings (python:int) – 词典的大小尺寸\r\n> embedding_dim (python:int) – 嵌入向量的维度，即用多少维来表示一个符号。\r\n\r\n有时在初始化时会被赋值会伴随着初始化过程。\r\n```py\r\nself.init_proposal_boxes = nn.Embedding(300, 4)\r\nnn.init.constant_(self.init_proposal_boxes.weight[:, :2], 0.5)\r\nnn.init.constant_(self.init_proposal_boxes.weight[:, 2:], 1.0)\r\n```\r\n\r\n【使用】<br />\r\n使用过程中，将`embed`直接当作向量来是使用","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.825Z"},{"title":"MatrixOpration","img":"","href":"ai/ai-1/3","des":"# 常用pytorch矩阵操作\r\n| 操作 | 指令 | 备注 |\r\n|-----|-----|-----|\r\n| 从list转变 | torch.cat($list) | 往往这类操作后面接列表生成式|\r\n| 获取邻域 |F.unfold( x, kernel_size=kernel_size, padding=padding, dilation=dilation ) | kernel_size领域大小，padding边距，dilation填充，padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2|\r\n| 邻域->图像 |F.fold( x, kernel_size=kernel_size, padding=padding, dilation=dilation ) | kernel_size领域大小，padding边距，dilation填充，padding = (kernel_size + (dilation - 1) * (kernel_size - 1)) // 2|\r\n|出现过的量|torch.uni","commend":0,"watch":0,"evaluate":0,"date":"2022-09-16T01:00:09.825Z"}]}