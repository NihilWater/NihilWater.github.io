{"articles":[{"title":"MEInst","img":"../../../img/article/2021-12-03-16-00-40.png","href":"ai/ai-8/2","des":"# MEInst\r\n\r\n## 信息\r\n\r\n文章标题：Mask Encoding for Single Shot Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2003.11712](https://arxiv.org/abs/2003.11712)\r\n\r\n发表时间：2020-03\r\n\r\n\r\n## 背景\r\n本文采用了紧凑掩膜编码，来进行单阶段实例分割任务，任务表面，使用了紧凑掩膜，对小目标的分割的效果相较二阶段无紧密掩膜的有较大提高，但对大目标，精度会少许的损失。\r\n\r\n## 创新点简介\r\n论文中指出，决定一个目标掩膜的关键像素主要分布在一个实例的边缘，而实例中占有大面积的部分是图像的主体部分，导致了信息的冗余。所以需要进行编码处理。\r\n> The discriminative pixels are mainly distributed along the object boundaries while most pixels in its body hold the properties of being category-c","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.033Z"},{"title":"sparse_RCNN","img":"../../../img/article/2022-03-15-15-25-43.png","href":"ai/ai-8/3","des":"# Sparse RCNN\r\n\r\n## 信息\r\n\r\n论文题目：Sparse R-CNN: End-to-End Object Detection with Learnable Proposals\r\n\r\n论文链接：[https://arxiv.org/abs/2011.12450](https://arxiv.org/abs/2011.12450)\r\n\r\n发表时间：2020-11\r\n\r\n## 创新\r\n\r\n使用可学习的100-300个边框来取代RPN（区域建议网络），实现了一个完全稀疏的端到端目标检测网络。\r\n\r\n\r\n## 详情\r\n\r\n### 稀疏和密集\r\n![](../../../img/article/2022-03-15-15-25-43.png)\r\n作者指出以前的目标检测都是每个特征像素做的，采用了“anchor boxes”机制，这会有十分密集的目标框（HWk个）产生，Faster RCNN 使用NMS筛选值的计算分类和边框回归的建议框，让一个密集的检测变得稀疏起来，但他仍然不能算是一个完全稀疏的目标检测方法（图b）。而本文作者所提出的Sparse RCNN则使用学习来的N(10","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.033Z"},{"title":"CommunityLearning","img":"../../../img/article/2021-12-10-14-59-50.png","href":"ai/ai-5/3","des":"# CommunityLearning\r\n\r\n## 信息\r\n\r\n文章标题：Weakly Supervised Instance Segmentation by Deep Community Learning\r\n\r\n文章链接：[https://arxiv.org/pdf/2001.11207.pdf](https://arxiv.org/pdf/2001.11207.pdf)\r\n\r\n发表时间：2020-01\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n(社区学习， community learning)这篇文章通过训练多个子模型用于多个子任务，end-to-end trainable deep neural network with active interactions between multiple tasks。\r\n\r\n社区学习与多任务学习不同，后者试图在没有参与模块之间紧密互动的情况下平行实现多个目标。\r\nThe community learning is different from multi-task learning that attempts to achiev","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.032Z"},{"title":"BoxInst变量","img":"../../../img/article/2021-11-01-10-35-26.png","href":"ai/ai-5/4","des":"# BoxInst 变量\r\n本文简单介绍BoxInst 模型中所使用到的关键变量\r\n\r\n## 信息\r\n\r\n论文标题: BoxInst: High-Performance Instance Segmentation with Box Annotations\r\n\r\n论文链接：[https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html](https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html)\r\n\r\n发布时间: 2020-12 (CVPR 2021)\r\n\r\n## 创新点总结\r\n提出了一种高性能、仅使用边界框注释进行训练的任务级实例","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.032Z"},{"title":"ISTR","img":"../../../img/article/2022-02-26-14-06-17.png","href":"ai/ai-5/5","des":"# ISTR\r\n\r\n## 信息 \r\n文章链接：[https://arxiv.org/abs/2105.00637](https://arxiv.org/abs/2105.00637)\r\n\r\n发表时间：2021-05\r\n\r\n![](../../../img/article/2022-02-26-14-06-17.png)\r\n\r\n## 创新点简介\r\n本文设计了一款TransFormer结构，类比了Spacer RCNN的思想，使用固定数目的RoI对目标进行界框检测和实例分割。\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.032Z"},{"title":"DETR","img":"../../../img/article/2022-03-11-16-20-09.png","href":"ai/ai-6/0","des":"# DETR\r\n\r\n## 信息\r\n\r\n论文标题：End-to-End Object Detection with Transformers\r\n\r\n论文链接：[https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)\r\n\r\n发表时间：2020-05\r\n\r\n\r\n## 创新\r\nDETR提出使用transformer，学习固定个数目标编码作为解码器的Q，来去除非极大化抑制的影响。具体来说首先使用CNN提取特征，然后将特征输入transformer的编码层，得到解码器的K和V，之后传入解码器，结合目标编码，产生解码结果，后通过MLP，映射到每一个对象的类别和边界框。和Faster RCNN转化为Mask RCNN一样，加入了mask head的DETR实现了分割任务。\r\n![](../../../img/article/2022-03-11-16-20-09.png)\r\n\r\n## 详情\r\n![](../../../img/article/2022-03-11-16-05-44.png)\r\n\r\n使用DETR进行实例分割\r","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.032Z"},{"title":"Queryinst","img":"","href":"ai/ai-6/1","des":"","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.032Z"},{"title":"SOLQ","img":"../../../img/article/2022-03-12-13-59-28.png","href":"ai/ai-6/2","des":"# SOLQ\r\n\r\n## 信息\r\n\r\n论文题目：SOLQ: Segmenting Objects by Learning Queries\r\n\r\n论文链接：[https://arxiv.org/abs/2106.02351](https://arxiv.org/abs/2106.02351)\r\n\r\n发表时间：2021-06\r\n\r\n## 创新\r\n\r\nSOLQ基于近期所提出的 DETR的实例分割的端到端框架，通过学习统一的查询来分割目标。不同于DETR通过引入类似于MaskRCNN中的Mask分支完成分割，SOLQ中的每个查询代表一个对象，里面包含了所有的class, location 和 mask信息。\r\n\r\n![](../../../img/article/2022-03-12-13-59-28.png)\r\n\r\n如上图所示，对于DETR，它通过设置一个长采样卷积结构完成对于实例mask的获取\r\n\r\n![](../../../img/article/2022-03-12-13-58-55.png)\r\n![](../../../img/article/2022-03-12-14-03-40.","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.032Z"},{"title":"CRF-RandWalk","img":"../../../img/article/2021-12-04-13-01-08.png","href":"ai/ai-4/1","des":"# CRF-RandWalk\r\n\r\n## 概率均匀化\r\n【本质】：设计一种概率转移方法，将图像中的密集概率向着整个物品进行扩散。也就是说通过计算两个特征像素之间的相似性，如果相似的话，就让当前像素上的概率和这个像素的概率进行均摊。\r\n\r\n## 条件随机场\r\n![](../../../img/article/2021-12-04-13-01-08.png)\r\n条件随机场通过“势函数”的引入，将初始的概率图进行转化。\r\n势函数包含了图片的像素色彩和位置信息\r\n\r\n## PCM\r\n![](../../../img/article/2021-12-04-13-18-36.png)\r\n图片来源于[https://arxiv.org/pdf/2004.04581v1](https://arxiv.org/pdf/2004.04581v1)\r\nPCM通过计算特征之间的相似程度，通过相似程度，进行概率转移。计算方式为余弦相似度。\r\n![](../../../img/article/2021-12-04-13-19-12.png)\r\n![](../../../img/article/2021-12-04","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.031Z"},{"title":"BAP_NAL","img":"../../../img/article/2021-11-03-21-39-58.png","href":"ai/ai-4/2","des":"# BAP_NAL\r\n\r\n## 信息\r\n\r\n文章标题：Background-Aware Pooling and Noise-Aware Loss forWeakly-Supervised Semantic Segmentation\r\n\r\n文章链接：\r\n\r\n发表时间：\r\n\r\n\r\n## 背景\r\n\r\n\r\n## 创新点简介\r\n①提出了BAP（背景感知池）方法，能够在边界框内分辨出前景和背景，相比于GAP方法，不会只考虑到局部。\r\n②我们引入了一个噪音感知损失（NAL）来训练CNN的语义分割。\r\n\r\n**效果**：\r\n在PASCAL VOC 2012数据集上使用DeepLab-V1（VGG-16）与最先进的方法进行定量比较，以mIoU计。粗体数字表示最好的性能，下划线的数字是第二好的。\r\n`Image-level labels (10K) with Saliency (3K)`\r\n| 方法              | 价值 | 测试 |\r\n|------------------|------|------|\r\n| SeeNetNIPS’18    | 61.1 | 60.7 |\r\n| Fick","commend":0,"watch":0,"evaluate":0,"date":"2022-03-25T10:41:49.031Z"}]}