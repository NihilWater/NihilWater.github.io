{"articles":[{"title":"MEInst","img":"../../../img/article/2021-12-03-16-00-40.png","href":"ai/ai-8/2","des":"# MEInst\r\n\r\n## 信息\r\n\r\n文章标题：Mask Encoding for Single Shot Instance Segmentation\r\n\r\n文章链接：[https://arxiv.org/abs/2003.11712](https://arxiv.org/abs/2003.11712)\r\n\r\n发表时间：2020-03\r\n\r\n\r\n## 背景\r\n本文采用了紧凑掩膜编码，来进行单阶段实例分割任务，任务表面，使用了紧凑掩膜，对小目标的分割的效果相较二阶段无紧密掩膜的有较大提高，但对大目标，精度会少许的损失。\r\n\r\n## 创新点简介\r\n论文中指出，决定一个目标掩膜的关键像素主要分布在一个实例的边缘，而实例中占有大面积的部分是图像的主体部分，导致了信息的冗余。所以需要进行编码处理。\r\n> The discriminative pixels are mainly distributed along the object boundaries while most pixels in its body hold the properties of being category-c","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.520Z"},{"title":"sparse_RCNN","img":"../../../img/article/2022-03-15-15-25-43.png","href":"ai/ai-8/3","des":"# Sparse RCNN\r\n\r\n## 信息\r\n\r\n论文题目：Sparse R-CNN: End-to-End Object Detection with Learnable Proposals\r\n\r\n论文链接：[https://arxiv.org/abs/2011.12450](https://arxiv.org/abs/2011.12450)\r\n\r\n发表时间：2020-11\r\n\r\n## 创新\r\n\r\n使用可学习的100-300个边框来取代RPN（区域建议网络），实现了一个完全稀疏的端到端目标检测网络。\r\n\r\n\r\n## 详情\r\n\r\n### 稀疏和密集\r\n![](../../../img/article/2022-03-15-15-25-43.png)\r\n\r\n作者指出以前的目标检测都是每个特征像素做的，采用了“anchor boxes”机制，这会有十分密集的目标框（HWk个）产生，Faster RCNN 使用NMS筛选值的计算分类和边框回归的建议框，让一个密集的检测变得稀疏起来，但他仍然不能算是一个完全稀疏的目标检测方法（图b）。而本文作者所提出的Sparse RCNN则使用学习来的N(","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.520Z"},{"title":"Can Vision Transformers Learn without Natural Images","img":"","href":"ai/ai-9/0","des":"# Vision Transformers Learn without Natural Images\r\n\r\n\r\n## 摘要\r\n\r\n【函数驱动的监督学习】使用了 FDSL,(Formula-Driven Supervised Learning)函数驱动的监督学习。先前的FDSL主要是产生了形状不同的形状的图形的物体，进行训练。在本文中作者又引入了颜色和斑块来进行训练。\r\n\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.520Z"},{"title":"introduction","img":"","href":"ai/ai-10/0","des":"# 图卷积神经网络\r\n## 意义\r\n使用神经网络来表达一张图上的信息。图相较于其他的数据结构，存在更加明显的结构特性。一张图的信息包含有4个方面，顶点的信息，边的信息，图整体的信息，图的连接信息。如今，大部分GNN在做的事情就是以一张图片的这些信息作为输入，得到一张输出图，输出图的结构信息与原图一样，但是顶点信息，边信息，整张图的信息表达会发生改变。\r\n\r\n## 信息的表达\r\n对于顶点信息，我们可以使用一个向量来进行表示。\r\n\r\n对于每一条边，我们同样可以使用一个向量来表示。\r\n对于全局信息，我们可以使用所有点的均值与所有边的均值进行表示，也可以使用一个和全部节点相连接的伪节点进行信息的表达。\r\n对于连接性，我们可以使用邻接表或者邻接矩阵来表示。\r\n\r\n## 案例说明\r\n【顶点分类问题】：已知一张图上有若干节点，需要对这些节点进行分类。\r\n① 最简单的方式，可能我们已经有了节点的向量表达，所以只需要对每个节点做一次全连接+softmax之类的分类网络就可以表示信息了。\r\n② 信息转化，假设顶点没有合理的向量表达，或者表达能力较弱，我们可以用边的","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.520Z"},{"title":"BoxInst变量","img":"../../../img/article/2021-11-01-10-35-26.png","href":"ai/ai-5/4","des":"# BoxInst 变量\r\n本文简单介绍BoxInst 模型中所使用到的关键变量\r\n\r\n## 信息\r\n\r\n论文标题: BoxInst: High-Performance Instance Segmentation with Box Annotations\r\n\r\n论文链接：[https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html](https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html)\r\n\r\n发布时间: 2020-12 (CVPR 2021)\r\n\r\n## 创新点总结\r\n提出了一种高性能、仅使用边界框注释进行训练的任务级实例","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"ISTR","img":"../../../img/article/2022-02-26-14-06-17.png","href":"ai/ai-5/5","des":"# ISTR\r\n\r\n## 信息 \r\n文章链接：[https://arxiv.org/abs/2105.00637](https://arxiv.org/abs/2105.00637)\r\n\r\n发表时间：2021-05\r\n\r\n![](../../../img/article/2022-02-26-14-06-17.png)\r\n\r\n## 创新点简介\r\n本文设计了一款TransFormer结构，类比了Spacer RCNN的思想，使用固定数目的RoI对目标进行界框检测和实例分割。\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"DETR","img":"../../../img/article/2022-03-11-16-20-09.png","href":"ai/ai-6/0","des":"# DETR\r\n\r\n## 信息\r\n\r\n论文标题：End-to-End Object Detection with Transformers\r\n\r\n论文链接：[https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)\r\n\r\n发表时间：2020-05\r\n\r\n\r\n## 创新\r\nDETR提出使用transformer，学习固定个数目标编码作为解码器的Q，来去除非极大化抑制的影响。具体来说首先使用CNN提取特征，然后将特征输入transformer的编码层，得到解码器的K和V，之后传入解码器，结合目标编码，产生解码结果，后通过MLP，映射到每一个对象的类别和边界框。和Faster RCNN转化为Mask RCNN一样，加入了mask head的DETR实现了分割任务。\r\n\r\n![](../../../img/article/2022-03-11-16-20-09.png)\r\n\r\n## 详情\r\n![](../../../img/article/2022-03-11-16-05-44.png)\r\n\r\n使用DETR进行实例分","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"Queryinst","img":"","href":"ai/ai-6/1","des":"","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"SOLQ","img":"../../../img/article/2022-03-12-13-59-28.png","href":"ai/ai-6/2","des":"# SOLQ\r\n\r\n## 信息\r\n\r\n论文题目：SOLQ: Segmenting Objects by Learning Queries\r\n\r\n论文链接：[https://arxiv.org/abs/2106.02351](https://arxiv.org/abs/2106.02351)\r\n\r\n发表时间：2021-06\r\n\r\n## 创新\r\n\r\nSOLQ基于近期所提出的 DETR的实例分割的端到端框架，通过学习统一的查询来分割目标。不同于DETR通过引入类似于MaskRCNN中的Mask分支完成分割，SOLQ中的每个查询代表一个对象，里面包含了所有的class, location 和 mask信息。\r\n\r\n![](../../../img/article/2022-03-12-13-59-28.png)\r\n\r\n如上图所示，对于DETR，它通过设置一个长采样卷积结构完成对于实例mask的获取\r\n\r\n![](../../../img/article/2022-03-12-13-58-55.png)\r\n\r\n![](../../../img/article/2022-03-12-14-03-4","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"},{"title":"SETR","img":"../../../img/article/2022-03-11-14-59-06.png","href":"ai/ai-7/0","des":"# SETR\r\n\r\n## 信息\r\n\r\n论文题目：Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers\r\n\r\n文章链接：[https://arxiv.org/abs/2012.15840](https://arxiv.org/abs/2012.15840)\r\n\r\n发表时间：2020-12 \r\n\r\n## 创新点简介\r\nSETR使用transformer设计了一个端到端的语义分割网络，首先将原图切割为若干 16x16 个窗口，把其中的像素进行线性映射，得到一维编码，然后使用24层transformer的编码器来完成对于图像特征的提取，然后使用卷积做上采样操作，得到最终结果。\r\n\r\n![](../../../img/article/2022-03-11-14-59-06.png)\r\n\r\n## 优点\r\n是语义分割领域的一次创行，将transformer引入到了语义分割领域中。\r\n\r\n## 存在的问题\r\n切割的窗口过大，语义信息不仅准。\r\n","commend":0,"watch":0,"evaluate":0,"date":"2022-03-26T11:42:28.519Z"}]}